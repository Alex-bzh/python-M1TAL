{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51cb8e3f-0369-47ba-b219-9257137b9e5d",
   "metadata": {},
   "source": [
    "# Fondamentaux de l’entraînement de modèles pour l’apprentissage supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f3a8a-aad9-409b-a6df-f1bd6caed41b",
   "metadata": {},
   "source": [
    "Jusqu’à présent, nous avons abordé les concepts essentiels de l’apprentissage supervisé très simplement, en les répartissant dans des étapes incontournables de tout projet de *machine learning*. De la constitution du jeu de données à l’entraînement du modèle en passant par la visualisation des interactions entre les variables explicatives et leur pré-traitement (recodage, mise à l’échelle, gestion des données manquantes…), il est en quelques manipulations possible d’obtenir des résultats satisfaisants avec les outils de *Scikit-Learn* dans la mesure où l’on est certain·es de disposer de données fiables et d’avoir fixé un objectif compréhensible.\n",
    "\n",
    "La réalité est plus nuancée. Si notre volonté n’est pas de dresser un panorama exhaustif des techniques de paramétrage d’un modèle d’apprentissage et de leurs subtilités, pour cela nous renvoyons à des ouvrages plus complets comme celui de Aurélien Géron, [*Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/), notre intention est d’infuser un certain nombre de réflexes propres à éviter les principaux écueils inhérents aux méthodes statistiques.\n",
    "\n",
    "Commençons par charger les librairies nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522a31-de37-42e3-a1ec-a22cf76e6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ad19c-f0a3-457f-9c7d-ea5051a99adc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Du problème de l’ajustement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a539e32-9b95-4eeb-8d62-933964c96ed0",
   "metadata": {},
   "source": [
    "Nous avons souvent évoqué les difficultés rencontrées par les modèles d’apprentissage pour s’ajuster aux données sans vraiment expliquer concrètement les deux cas de figure qui peuvent se présenter :\n",
    "- Le **sous-ajustement** (*underfitting*), survenant lorsque le modèle ne parvient pas à percevoir la forme des données ;\n",
    "- le **sur-ajustement** (*overfitting*), souvent caractérisé par des erreurs de généralisation bien plus importantes que celles d’entraînement.\n",
    "\n",
    "L’objectif n’est donc pas d’obtenir le meilleur score sur le jeu d’entraînement ou, pire, sur le jeu de test, mais bien de trouver la zone idéale qui minimise l’écart entre les erreurs d’entraînement et de généralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7258a-0fb7-4fe7-8144-09942876946b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Facteur de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a6aca-bb42-4023-9038-70bf75a7a795",
   "metadata": {},
   "source": [
    "Avant d’entrer dans le vif du sujet, abordons un piège fondamental qui peut apparaître dès la définition du projet de *machine learning*. Imaginons que l’on souhaite modéliser un programme qui permette de prédire l’ampleur du bec d’un manchot et, comme variable explicative, nous retenons son poids.\n",
    "\n",
    "Chargeons les données sur le recensement de trois espèces de manchots de l’Antarctique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc19fa2-4087-4c34-998d-71b3819e3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/penguin-census.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f4c2f-b8d7-4699-96f9-f674cfa8544f",
   "metadata": {},
   "source": [
    "Un modèle simple de régression linéaire nous apprend qu’il existe une corrélation négative entre les deux variables, si bien que le bec d’un manchot s’affine à mesure que sa masse corporelle augmente. Les chiffres ne mentent pas et, si l’on considère en prime l’intervalle de confiance à 95 %, la marge d’erreur est somme toute raisonnable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0ab21-c854-489f-8572-b0a170ea1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.regplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86a6fe-6826-4310-b290-cc944d569875",
   "metadata": {},
   "source": [
    "La déduction nous semble malgré tout contre-intuitive. On aurait plutôt tendance à penser que les propriétés physiques de tout organisme biologique croissent proportionnellement à sa masse, non ?\n",
    "\n",
    "Essayons de comprendre l’erreur de méthodologie que nous avons commise. Sur le graphique que nous venons d’afficher se distinguent deux groupes de points. Peut-être existe-t-il une différence entre les individus mâles et les individus femelles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2439979-4f25-4cf6-8718-254c9748ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"sex\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc4ba-4f12-4674-b7d4-881279420dbf",
   "metadata": {},
   "source": [
    "Eh bien, non, cette hypothèse nous conforte dans notre erreur. Avant de supposer une différenciation de genre, rappelons-nous plutôt que la grande famille des manchots est subdivisée en plusieurs espèces avec des disparités physiques fortes et regardons le comportement de notre modèle linéaire à la lumière de ce nouveau facteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92162682-09d3-42c5-94c3-01417eb0d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"species\", hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cbd24-5f46-4c62-85d6-2555e916b3fc",
   "metadata": {},
   "source": [
    "D’une corrélation négative entre la masse et l’épaisseur du bec d’un manchot nous sommes passés à une corrélation positive et avons évité de graves erreurs de généralisation au moment de la production de notre modèle.\n",
    "\n",
    "Dans notre exemple, l’espèce d’appartenance d’un manchot est ce que l’on nomme un facteur de confusion, en ce sens qu’elle influe non seulement sur la variable cible, l’épaisseur du bec, mais aussi sur la variable explicative, la masse corporelle. En effet, si nous nous permettons une analyse grossière, un manchot papou ne peut pas peser moins de 4 kgs et son bec ne dépassera pas les 18 mm d’épaisseur pour les mieux lotis quand celui d’un manchot Adélie peut atteindre les 22 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5f513-26bd-44f4-b6e6-bde85dc49906",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Erreurs d’entraînement et de généralisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36aa32-64bc-426a-b36d-f16d1c2809b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comparer les chiffres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3376f2-4696-45a0-81d1-21a44ba3b0ff",
   "metadata": {},
   "source": [
    "La compréhension des notions liées à l’ajustement d’un modèle passe par la comparaison des erreurs sur les jeux d’entraînement et de test. Prenons tout d’abord un ensemble de points à l’aspect sinusoïdal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da651b-9857-4ff0-8e50-56200e445bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deterministic purposes\n",
    "np.random.seed(42)\n",
    "\n",
    "# three hundred points\n",
    "X = np.linspace(0, 10, 300).reshape(-1, 1)\n",
    "\n",
    "# sinusoid function + noise\n",
    "y = np.sin(X) + np.random.rand(300, 1)\n",
    "\n",
    "# into a DF\n",
    "coords = pd.DataFrame({\n",
    "    'x': X[:, 0],\n",
    "    'y': y[:, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d56b5c-c304-4401-aca4-cf82ea429b5b",
   "metadata": {},
   "source": [
    "Si nous affichons un nuage de points, une forme se dessine clairement, nous laissant une vague idée sur la forme de la ligne qui devrait minimiser la fonction de coût :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c6918-ab9c-4a52-abcb-e4ea8a8270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(data=coords, x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77046e6d-1650-4106-af74-bc286bd03192",
   "metadata": {},
   "source": [
    "Constituons maintenant les jeux d’entraînement et de test selon une partition 80/20 et essayons d’entraîner dessus un modèle de régression linéaire que nous savons d’ores et déjà voué à l’échec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb05b8-b65b-4e60-9b28-b2a3dca34884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(coords[\"x\"].values.reshape(-1,1), coords[\"y\"], test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708afae-8119-4f3a-84a9-b61540b3ac1e",
   "metadata": {},
   "source": [
    "Les prédictions sont désastreuses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16d32e-32ff-4900-a0de-bcba61fb6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# plot test points\n",
    "ax = sns.scatterplot(x=X_test[:, 0], y=y_test)\n",
    "ax.plot(X_test, y_pred, color=\"orange\")\n",
    "_ = ax.set_title(f\"R2 scores: train = {model.score(X_train, y_train):.3f} ; test = {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a79f8-a21f-46dc-9d12-9c9ad62f092f",
   "metadata": {},
   "source": [
    "D’un côté, en étant inférieur sur les données de test, le $R^2$ score est conforme à nos attentes ; d’un autre côté, il est révélateur d’un modèle sévèrement sous-ajusté.\n",
    "\n",
    "Confirmons ce résultat en calculant maintenant l’erreur absolue moyenne (*mean absolute error*) et rappelons que si un score doit être le plus élevé possible, une erreur doit quant à elle être la plus faible possible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b16a09-e346-4cf2-83dd-ca9649491e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\n",
    "    f\"MAE (jeu d’entrainement) : {mae_train:.3f}\",\n",
    "    f\"MAE (jeu de test) : {mae_test:.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd03d3a-187e-4791-be43-a0d73a73160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(y[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fb24f-81e5-48b2-868a-5453aef7135a",
   "metadata": {},
   "source": [
    "Que l’erreur sur le jeu de test soit plus importante que sur le jeu d’entraînement est somme toute logique : on s’attend effectivement à ce que les prédictions soient de meilleure qualité sur des données déjà vue et que la généralisation se passe moins bien. Ceci dit, pour des valeurs de $y$ compris dans un intervalle $\\mathopen{[} -1 ; 2\\mathclose{]} $, une $\\text{MAE} > 0.6$ ne laisse aucun doute : le modèle est sous-ajusté.\n",
    "\n",
    "Reprenons nos efforts en entraînant désormais un modèle de régression polynomiale à haut degré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4225-f7ee-4c9b-8cfa-5efbdb37b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=25),\n",
    "    LinearRegression(),\n",
    ")\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "mae_test = mean_absolute_error(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702654f6-c1c1-4173-be85-e93c94b67fab",
   "metadata": {},
   "source": [
    "La MAE sur le jeu d’entraînement reste élevée tandis qu’elle a baissé sur le jeu de test au point de lui être maintenant inférieure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46dd1b-009d-4770-86d5-26f97a8f25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_test[:, 0], y=y_test, ax=ax)\n",
    "sns.lineplot(x=X_test[:, 0], y=y_test_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE: train = {mae_train:.3f} ; test = {mae_test:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8d84d-8c38-489c-8bd8-139e444385cf",
   "metadata": {},
   "source": [
    "Encore une fois on s’attendrait en fait à l’inverse d’un modèle justement entraîné, l’idée qu’il soit moins performant sur des données nouvelles étant tout à fait naturelle. Ici, c’est sans doute le signe que le modèle commence à surajuster. En tâtonnant un peu, on finirait par trouver qu’un polynôme de degré 7 ou 8 constitue le meilleur choix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1116176-88ea-4f62-8cb2-ffa463168da2",
   "metadata": {},
   "source": [
    "#### Améliorer l’estimation par la validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34382d97-7b3e-47d4-8196-3e8fc806ef66",
   "metadata": {},
   "source": [
    "En réalisant aveuglément les évaluations de nos modèles au moment des phases d’entraînement et de test, nous avons mis au jour quelques incertitudes quant à leur crédibilité. Observons l’ampleur de l’enjeu avec un modèle basé sur un arbre de décision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df468c6c-aca5-40ac-831e-43ae992bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "\n",
    "# plot\n",
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_train[:, 0], y=y_train, ax=ax)\n",
    "sns.lineplot(x=X_train[:, 0], y=y_train_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE (train set) = {mae_train:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8bcd13-3110-4ebc-95ac-963f843f1275",
   "metadata": {},
   "source": [
    "Une MAE à 0.0 ! Un score parfait qui nous satisferait si l’on n’était conscient·es de la nette tendance des arbres de décision à sur-ajuster. Le graphique est explicite : sans contrainte, le tracé suit tous les points du jeu d’entraînement.\n",
    "\n",
    "Dans la pratique, avant de passer à l’étape de généralisation, il convient de s’assurer que le modèle entraîné est fiable. Pour cela, rien de plus évident, il nous suffirait de découper le jeu d’entraînement en deux sous-ensembles avec la fonction `train_test_split()` : un pour l’entraînement effectif et l’autre pour la validation.\n",
    "\n",
    "*Scikit-Learn* propose un outil plus performant pour réaliser ce que l’on appelle une validation croisée en $K$ passes. C’est les fonctions `cross_validate()` ou `cross_val_score()` lorsque l’on n’est intéressé·es que par les métriques. Le procédé consiste à découper le *dataset* en $K$ parties puis à effectuer $K$ évaluations en prenant à chaque passe $K - 1$ sous-ensembles pour l’entraînement et le restant, qui ne sera jamais le même, pour la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c8eae-0e89-4f3b-b956-0fb9229b7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10 ; score = -MAE\n",
    "scores = cross_val_score(model, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "# -MAE into MAE\n",
    "scores = -scores\n",
    "\n",
    "print(\n",
    "    f\"MAE moyenne : {scores.mean():.3f}\",\n",
    "    f\"Écart-type : {scores.std():.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8600721-7dd2-4495-bcb4-67dcc25d7b82",
   "metadata": {},
   "source": [
    "Après validation croisée, notre modèle nous semble largement moins convaincant ! Il ne nous reste plus qu’à tout reprendre de zéro et à travailler sur les différentes solutions pour l’améliorer : changer d’algorithme, augmenter le nombre d’observations d’entraînement ou encore lui imposer des contraintes afin de le régulariser.\n",
    "\n",
    "**Remarque :** le paramètre `scoring` de la fonction `cross_val_score()` attend une fonction d’utilité, où la valeur la plus haute est considérée comme la meilleure, et non une fonction de coût, où la valeur la plus basse est réputée la plus forte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a9905-1dd0-4f58-8eff-497ebb0e137c",
   "metadata": {},
   "source": [
    "#### Visualiser les courbes de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87b9f5-a378-47d3-adda-96139041df20",
   "metadata": {},
   "source": [
    "Une bonne manière de se représenter les phénomènes de sous-ajustement et de sur-ajustement consiste à afficher les courbes de validation du modèle en fonction d’un paramètre avec la fonction `validation_curve()`. Dans notre exemple, nous avons utilisé un arbre de décision que l’on sait avoir tendance à sur-ajuster et nous sélectionnons deux paramètres réputés le régulariser : `max_depth` pour définir la profondeur maximale de l’arbre et `min_samples_leaf` pour fixer le nombre minimum d’observations à considérer dans un nœud de l’arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466eafb-b402-45a3-a218-8dbb59c24ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# several values for each param\n",
    "max_depth = [1, 4, 5, 7, 10, 25]\n",
    "min_samples_leaf = [1, 3, 5, 7, 10, 15]\n",
    "\n",
    "# param = max_depth ; score = -MAE\n",
    "max_depth_train_scores, max_depth_test_scores = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name=\"max_depth\", param_range=max_depth,\n",
    "    cv=10, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "# param = min_samples_leaf ; score = -MAE\n",
    "min_samples_leaf_train_scores, min_samples_leaf_test_scores = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name=\"min_samples_leaf\", param_range=min_samples_leaf,\n",
    "    cv=10, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "# -MAE into MAE\n",
    "max_depth_train_errors, max_depth_test_errors = -max_depth_train_scores, -max_depth_test_scores\n",
    "min_samples_leaf_train_errors, min_samples_leaf_test_errors = -min_samples_leaf_train_scores, -min_samples_leaf_test_scores\n",
    "\n",
    "# plot\n",
    "figure, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n",
    "\n",
    "sns.lineplot(x=max_depth, y=max_depth_train_errors.mean(axis=1), ax=ax1)\n",
    "sns.lineplot(x=max_depth, y=max_depth_test_errors.mean(axis=1), ax=ax1)\n",
    "sns.lineplot(x=min_samples_leaf, y=min_samples_leaf_train_errors.mean(axis=1), ax=ax2)\n",
    "sns.lineplot(x=min_samples_leaf, y=min_samples_leaf_test_errors.mean(axis=1), ax=ax2)\n",
    "\n",
    "ax1.set(\n",
    "    title=\"Paramètre : max_depth\",\n",
    "    xlabel=\"Profondeur maximale de l’arbre\",\n",
    "    ylabel=\"Erreur absolue moyenne\"\n",
    ")\n",
    "ax2.set(\n",
    "    title=\"Paramètre : min_samples_leaf\",\n",
    "    xlabel=\"Nombre minimum d’observations dans un nœud\",\n",
    "    ylabel=\"Erreur absolue moyenne\"\n",
    ")\n",
    "ax1.legend(title=\"Jeux de données\", labels=[\"entraînement\", \"validation\"])\n",
    "ax2.legend(title=\"Jeux de données\", labels=[\"entraînement\", \"validation\"])\n",
    "\n",
    "figure.suptitle(\"Courbes de validation de l’arbre de décision\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ea4b0-6c2d-4460-81bd-947e0b52aef1",
   "metadata": {},
   "source": [
    "L’analyse des graphiques nous révèle les valeurs idéales pour les paramètres de régularisation :\n",
    "- `max_depth` : 5\n",
    "- `min_samples_leaf`: 3\n",
    "\n",
    "Pour chacun d’eux, nous distinguons trois zones :\n",
    "1. Tant que la valeur du paramètre est inférieure à celle idéale, le modèle sous-ajuste. Il n’a pas assez de degré de liberté pour comprendre toutes les variations de la variable cible. La MAE est forte pour les deux tracés.\n",
    "2. Lorsque le tracé de la MAE pour le jeu de validation cesse de décroître, le modèle a atteint la zone où il généralise le mieux.\n",
    "3. Sitôt que la valeur idéale est dépassée, le modèle s’ajuste de plus en plus étroitement aux données d’entraînement et généralise de moins en moins bien.\n",
    "\n",
    "À ces observations, il faut en rajouter une sur l’écart entre les deux tracés. Dans le cas du paramètre `min_samples_leaf`, on serait tenté·es de retenir la valeur 5 comme la meilleure puisque la MAE sur le jeu de validation reste stable alors qu’elle baisse sur le jeu d’entraînement. En fait, cet écart montre que le modèle est en train de sur-ajuster, aussi est-il préférable d’opter pour la valeur qui minimise l’écart.\n",
    "\n",
    "**Remarque :** les paramètres ont été testés individuellement, sans essayer les différentes combinaisons entre eux. Nous verrons plus loin une méthode pour effectuer une recherche des meilleurs réglages des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb17c2-578b-4956-ba8d-bd57970ea854",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Entraîner, tester, valider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80b04e-ba47-462a-b89f-b690c55ebb2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sélectionner les variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ebd24-c115-4d72-9186-77e145bd6f5e",
   "metadata": {},
   "source": [
    "En fonction de l’objectif défini pour le programme d’apprentissage, il sera nécessaire de laisser de côté certaines variables du jeu de données. Deux perspectives peuvent nous aider à faire le tri :\n",
    "- Une expertise personnelle ou glanée auprès de spécialistes de la thématique ;\n",
    "- l’étude de la corrélation entre les variables explicatives et la variable cible.\n",
    "\n",
    "Laissons de côté la première pour expliquer la notion de corrélation entre variables. Si elles sont à l’origine réputées indépendantes, la recherche de corrélation va mettre en évidence une relation dont la prépondérance sera calculée par un coefficient. Rappelons qu’une corrélation n’est surtout pas la preuve de l’existence d’un lien de cause à effet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0494f-f51b-4187-a1a9-1277147d074a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Corrélation entre variables quantitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f83d6d-565e-4126-8a82-22ca3ede5672",
   "metadata": {},
   "source": [
    "Pour illustrer notre propos, chargeons plutôt en mémoire un jeu de données sur la satisfaction à l’égard de la vie des femmes des pays de l’OCDE et retenons uniquement quelques indicateurs pour des raisons de lisibilité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9a6b2-38cf-4b6c-9e70-bbd6e1c76b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset without na\n",
    "df = pd.read_csv(\"./data/better-life-index-women-2021.csv\", index_col=[0])\n",
    "es_edua_mean = int(df[\"ES_EDUA\"].mean())\n",
    "df[\"ES_EDUA\"].fillna(es_edua_mean, inplace=True)\n",
    "\n",
    "target = \"SW_LIFS\"\n",
    "features = [\"HS_LEB\", \"ES_EDUA\", \"SC_SNTWS\", \"PS_REPH\"]\n",
    "\n",
    "data = df[features + [target]]\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90c83b-d291-4a9f-8ece-41fda7e2aa48",
   "metadata": {},
   "source": [
    "Pour des variables quantitatives, nous pouvons invoquer la méthode `.corr()` qui dresse une matrice de corrélation avec, pour mesure par défaut, le $R$ de Pearson, où 0 indique une absence de corrélation et -1 et 1 une corrélation forte, qu’elle soit négative ou positive :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f96b53-4d75-4663-ad98-720e6c46d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method=\"pearson\"\n",
    "correlation_matrix = data.corr()\n",
    "# heatmap\n",
    "_ = sns.heatmap(correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a252a-fb13-4cc0-ad73-f7651f0d5e5d",
   "metadata": {},
   "source": [
    "Dans notre exemple, nous observons une corrélation positive assez forte entre la satisfaction à l’égard de la vie d’une part et, d’autre part, la qualité du réseau social ou l’espérance de vie. À l’inverse, le taux d’homicide semble influer négativement dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae55ae-9bc0-4188-bf6c-6c81c849e98e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Corrélation entre variables qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585f9b1-7421-4412-a8ba-307340333f6a",
   "metadata": {},
   "source": [
    "Pour des variables qualitatives, il n’existe malheureusement pas d’outil clé en main, mais nous pouvons nous reposer sur des tests statistiques éprouvés. Prenons une autre enquête, sur la satisfaction de patients relativement à leur séjour à l’hôpital :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abb557-4699-48cb-ad9c-b2ee2da07da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data without na\n",
    "df = pd.read_csv(\"./data/satisfaction-hopital.csv\", sep=\";\")\n",
    "df.fillna(method=\"pad\", inplace=True)\n",
    "\n",
    "target = \"recommander\"\n",
    "features = [\"score.information\", \"score.relation\", \"amelioration.moral\", \"amelioration.sante\", \"sexe\", \"age\", \"profession\", \"service\"]\n",
    "\n",
    "data = df[features + [target]]\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf16d8c-888d-48f3-913a-7853f10d9954",
   "metadata": {},
   "source": [
    "En dépit de leur allure numérique, la majorité des variables sont qualitatives. Retenons *service* et *recommander* en construisant une table de contingence à l’aide de la méthode `.crosstable()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e18c2c-5867-4636-83d3-9d55f70b9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(data.service, data.recommander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc93d23-57e1-430a-add6-28da708b7044",
   "metadata": {},
   "source": [
    "Émettons maintenant l’hypothèse nulle $H_0$ d’indépendance entre les deux variables, hypothèse que nous sommes prêt·es à rejeter au seuil de 5 %, et effectuons comme mesure le test du $\\chi^2$ (*Chi-squared test*) en nous reposant sur la fonction `chi2_contingency()` du module `stats` de la bibliothèque *SciPy* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e3c35-86ce-4252-af59-eb723c3f71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, exp = chi2_contingency(contingency_table)\n",
    "print(f\"Valeur-p : {p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28bac5-7b66-4d09-bb68-d68936ba4c41",
   "metadata": {},
   "source": [
    "La valeur-p (*p-value*) est bien inférieure au seuil de 5 %, ce qui nous autorise à rejeter notre hypothèse nulle et à déclarer que la corrélation entre les variables *service* et *recommander* est statistiquement significative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156bdbd-6c78-4826-9ff2-0104d9473604",
   "metadata": {
    "tags": []
   },
   "source": [
    "### L’échantillonnage stratifié"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225bf31-11a2-4fdd-ae54-a6651dac901c",
   "metadata": {},
   "source": [
    "Dans le précédent chapitre, nous avons évoqué l’importance d’évaluer la performance du jeu d’entraînement avant de passer à l’étape de généralisation, sans pour autant préciser la manière de le construire proprement. Nous nous sommes même contenté d’une méthode purement aléatoire en faisant appel à la fonction `train_test_split()`. Si elle est satisfaisante en présence d’un volume considérable d’observations, le risque d’introduire un biais d’échantillonnage n’est pas négligeable lorsque les données manquent.\n",
    "\n",
    "Imaginons que, renseignements pris auprès de spécialistes du domaine, nous apprenons que la profession des patient·es est un facteur déterminant du score de satisfaction qu’ils et elles attribueront à leur séjour à l’hôpital. Regardons maintenant la distribution des individus par catégorie professionnelle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedde49-3f84-4d22-8802-827360d9cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.countplot(data=X, x=\"profession\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf30c38-876b-40d5-b247-46b97d3d9611",
   "metadata": {},
   "source": [
    "Au vu des disparités, nous souhaitons regrouper les professions dans des catégories plus larges qui n’ont de sens que du point de vue mathématique. Pour cette raison, nous n’expliquerons pas les indices attribués aux catégories professionnelles dans l’enquête et reportons ci-dessous uniquement les regroupement proposés :\n",
    "- 1, 2 et 8 ensemble ;\n",
    "- 3 ;\n",
    "- 4 avec 7 ;\n",
    "- 5 avec 6.\n",
    "\n",
    "Recodons à présent la catégorie dans une variable *prof_cat* et regardons la nouvelle répartition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca91681-3afc-4c35-8fe1-6d42a8e4bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X[\"profession\"] == 3, \"prof_cat\"] = \"3\"\n",
    "X.loc[(X[\"profession\"] == 1) | (X[\"profession\"] == 2) | (X.profession == 8), \"prof_cat\"] = \"1, 2 et 8\"\n",
    "X.loc[(X[\"profession\"] == 4) | (X[\"profession\"] == 7), \"prof_cat\"] = \"4 et 7\"\n",
    "X.loc[(X[\"profession\"] == 5) | (X[\"profession\"] == 6), \"prof_cat\"] = \"5 et 6\"\n",
    "\n",
    "_ = sns.countplot(data=X, x=\"prof_cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dde590-ae18-4104-8e0d-e2749ec3f27a",
   "metadata": {},
   "source": [
    "Les catégories sont plus équilibrées. Il ne nous reste plus qu’à constituer les différents jeux dont nous avons besoin pour analyser les écarts engendrés par la répartition aléatoire des observations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e8574-a76b-45fc-9fc8-af5f6eb7a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# prop data set - prop train set\n",
    "X[\"prof_cat\"].value_counts() / len(X) - X_train[\"prof_cat\"].value_counts() / len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822e2e2-a5a6-4126-b384-7465004d1471",
   "metadata": {},
   "source": [
    "Les différences ne sont guère notables dans ce cas de figure, mais comme nous voulons que notre jeu d’entraînement reflète la même répartition de patient·es en fonction de leur profession que dans le jeu complet, nous optons pour un échantillonnage stratifié. Il se trouve que la fonction `train_test_split()` accepte un argument `stratify` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65981d-552a-4f5e-8c4e-ceb1b0fa88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, stratify=X[\"prof_cat\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21180be9-d8f7-4594-a21a-24d5cb2bd03d",
   "metadata": {},
   "source": [
    "Grâce à cette astuce, les écarts étant désormais infimes, nous sommes assuré·es de la représentativité de notre jeu d’entraînement sur le critère de la catégorie professionnelle des individus statistiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea78a31-a75b-47bd-ae41-f43e7edee56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"prof_cat\"].value_counts() / len(X) - X_train_strat[\"prof_cat\"].value_counts() / len(X_train_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e605bc19-1362-4111-bc03-8690b91560c1",
   "metadata": {},
   "source": [
    "Et pour rendre plus propres nos jeux de données, nous pouvons supprimer la variable *prof_cat* créée artificiellement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc8c03-c45e-4d62-b8f8-d6b572513bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [X, X_train, X_train_strat, X_test, X_test_strat]:\n",
    "    dataset.drop(columns=\"prof_cat\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da68854e-401f-4ea1-b6dd-585217af90ad",
   "metadata": {},
   "source": [
    "### Déterminer le gain de données supplémentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be9ffdc-a8aa-4d3f-8d27-e80d4aad7c14",
   "metadata": {},
   "source": [
    "On ne cesse de le répéter, c’est comme un proverbe : plus on a de données pour l’entraîner, meilleur sera le modèle. Dans l’absolu, c’est la bonne règle à suivre, mais depuis que l’on a mentionné le problème du sur-ajustement, la question ne nous paraît plus aussi simple.\n",
    "\n",
    "Déjà, sur la partition du 80/20, est-il si judicieux de suivre une norme relative quelle que soit la taille du jeu de données ? Pour une enquête comprenant cinq cents observations, en dédier quatre cents à l’entraînement et en conserver cent pour les tests nous paraît tomber sous le sens, mais qu’en serait-il si l’on disposait d’un million d’observations ? En faudrait-il vraiment huit cent mille pour s’assurer d’obtenir un bon modèle ? Et si au contraire nous n’avons que très peu de données, de l’ordre de la centaine, peut-on se contenter d’une vingtaine pour les tests ?\n",
    "\n",
    "Ensuite, au moment d’évaluer notre modèle, comment résister à la tentation de ne pas améliorer encore un peu plus son score en augmentant le volume du jeu d’entraînement ? Les gains marginaux, à l’échelle de la décimale, peuvent avoir au final leur importance.\n",
    "\n",
    "Afin de décider de cette frontière, laissons-nous guider par les courbes d’apprentissage que l’on peut dessiner à partir des résultats de la fonction `learning_curve()`. Commençons par entraîner sur les données de la satisfaction à l’hôpital un modèle simple basé sur la classification naïve bayésienne :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05975a7a-7acc-4cec-9f7c-e25a396abf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "_ = model.fit(X_train_strat, y_train_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436b01cc-a9ed-494a-98d6-61a31ea7479a",
   "metadata": {},
   "source": [
    "Définissons ensuite une stratégie de validation croisée grâce à la classe `ShuffleSplit` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa1c66-ad58-4458-bed6-aafd91383c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = ShuffleSplit(n_splits=30, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a293ce3f-f78e-4c15-8eb2-c5d1b5f1d1be",
   "metadata": {},
   "source": [
    "L’idée étant de connaître l’apport d’une fraction de données supplémentaires pour l’entraînement de notre modèle, nous établissons une règle linéaire qui ajoute à chaque itération 10 % du total :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc5de93-1f3a-4547-a9ba-9f8f560dd20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.linspace(0.1, 1, num=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0efdbc8-c5f4-49e6-9c20-8750c2c6590f",
   "metadata": {},
   "source": [
    "Lançons la fonction qui permet de récupérer les scores pour chaque tranche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a440d85-7ae4-4332-9d3c-bad24bfc3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_jobs: one cpu only\n",
    "train_size, train_scores, test_scores = learning_curve(model, X, y, train_sizes=train_sizes, cv=cv, n_jobs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda95617-5b25-4033-8956-fa6ce1c48afa",
   "metadata": {},
   "source": [
    "Affichons le graphique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b51390-972d-4054-b689-16720b2a55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.lineplot(x=train_size, y=train_scores.mean(axis=1), ax=ax)\n",
    "sns.lineplot(x=train_size, y=test_scores.mean(axis=1), ax=ax)\n",
    "\n",
    "ax.set(\n",
    "    title=\"Courbes d’entraînement du classifieur naïf bayésien\",\n",
    "    xlabel=\"Nombre d’observations\",\n",
    "    ylabel=\"Exactitude\"\n",
    ")\n",
    "ax.legend(title=\"Jeux de données\", labels=[\"entraînement\", \"test\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12997591-a686-443a-92b1-075cade27199",
   "metadata": {},
   "source": [
    "Si l’on suit la courbe bleue qui matérialise la performance du modèle sur le jeu d’entraînement, nous comprenons bien qu’il sur-ajuste au début de l’apprentissage (> 75 % d’exactitude pour < 50 observations) avant de stagner autour de 67 % à partir de 300 observations. Pour le jeu de test, on observe deux pics à 220 et 300 observations puis une tendance à la baisse qui ne semble pas s’inverser. Rappelons également que l’objectif est de minimiser l’écart entre les deux courbes et nous pourrons en déduire que le nombre idéal d’observations à retenir pour le jeu d’entraînement n’est pas de 427 (80 % de `len(X)`), mais plutôt autour de 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63f0a1-ca6f-4c2b-aa0a-96a6112f336c",
   "metadata": {},
   "source": [
    "## Régulariser un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef62c5-8f79-46f9-8d27-d00b40d366c8",
   "metadata": {},
   "source": [
    "Nous l’avons souvent évoqué, les différentes familles d’algorithmes d’apprentissage viennent avec leurs contraintes et leurs limites. Les arbres de décision, par exemple, montrent tout de suite des résultats hautement satisfaisants mais au prix d’un sur-ajustement caractéristique. À l’inverse, un modèle linéaire à faible degré de liberté sera certes moins sensible aux données mais échouera à capter leur forme.\n",
    "\n",
    "Si déjà le choix de l’algorithme d’apprentissage est déterminant, il est en plus possible de le paramétrer afin de réduire ses défauts et d’obtenir un compromis entre **le biais** et **la variance**. Cette étape dite de régularisation consiste non seulement à trouver la bonne combinaison entre les hyperparamètres mais aussi à déterminer la meilleure valeur à leur attribuer pour optimiser les performances du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4aebb-0523-4f74-a446-de921570f23b",
   "metadata": {},
   "source": [
    "### Un hyperparamètre ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e255892-7e30-4754-a569-0edc9cfd34b9",
   "metadata": {},
   "source": [
    "Les algorithmes d’apprentissage de *Scikit-Learn* sont fournis avec des paramètres fixés avec une valeur par défaut. Par exemple, la classe `DecisionTreeClassifier` expose un paramètre `min_samples_split` fixé à 2 par défaut. Deux étant le nombre minimum d’observations requis avant de scinder un nœud de l’arbre de décision, un parti pris qui incite le modèle à sur-ajuster.\n",
    "\n",
    "Ces paramètres sont nommés **hyperparamètres** pour bien les différencier des autres en ce sens qu’ils influent directement sur la procédure d’apprentissage. Plutôt que de les lister pour chaque classe, nous renvoyons à la documentation de *Scikit-Learn* et allons plutôt explorer les moyens de les révéler et de les évaluer.\n",
    "\n",
    "Reprenons l’enquête de satisfaction à l’hôpital pour évaluer les performances d’un arbre de décision simple :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da038d9-da98-4d4c-b4a3-04c2b711c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "\n",
    "scores = cross_val_score(model, X_train_strat, y_train_strat)\n",
    "print(f\"Exactitude du modèle par validation croisée : {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327b49fb-b3f7-4f80-bd31-e17da0b9425c",
   "metadata": {},
   "source": [
    "Nous ne commenterons pas la performance du modèle, pour parler plutôt de la méthode `.get_params()` qui fournit un dictionnaire de ses hyperparamètres et des valeurs attribuées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a329b2d-6acb-4786-8e04-ff20df73a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16d2f1a-3d94-42df-a974-0d83b24b0026",
   "metadata": {},
   "source": [
    "La méthode `.set_params()` quant à elle permet de modifier les valeurs définies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca718b1-e7ee-4de4-ab70-dbdb513b9c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for max_depth in range(1, 5):\n",
    "    model.set_params(max_depth=max_depth)\n",
    "    scores = cross_val_score(model, X_train_strat, y_train_strat)\n",
    "    print(f\"Exactitude pour `max_depth` = {max_depth} : {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac87796-c6e5-4d57-8de5-10dc97b77339",
   "metadata": {},
   "source": [
    "### Rechercher les meilleurs réglages automatiquement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbc2e58-43e0-4424-9c6f-96c9b8e8e164",
   "metadata": {},
   "source": [
    "Rechercher manuellement les réglages des hypermaramètres serait d’autant plus fastidieux que, bien souvent, on ne se limite pas à un seul modèle mais on en compare plusieurs.\n",
    "\n",
    "La solution consiste à effectuer une recherche par quadrillage en appelant la classe `GridSearchCV` de *Scikit-Learn*. La première étape consiste à définir une liste des différentes combinaisons d’hyperparamètres et de leurs valeurs à tester :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bced31-b0ef-4af4-b34e-e46668e7285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\"max_depth\": range(1,3), \"max_features\": range(1,3)},\n",
    "    {\"max_depth\": range(1,3), \"max_features\": range(1,3), \"min_samples_leaf\": range(2,10)}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5d58dd-11cf-45d0-94aa-c89d8e42d7ce",
   "metadata": {},
   "source": [
    "Deuxièmement, il faut transmettre la grille des paramètres au constructeur de la classe et l’entraîner comme un estimateur normal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1108da7-8243-40be-af51-a54b20e9d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "_ = grid_search.fit(X_train_strat, y_train_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c848c534-4f03-4eb2-9174-053974eb078b",
   "metadata": {},
   "source": [
    "En retour, la propriété `.best_params_` fournit les meilleures combinaisons d’hyperparamètres avec leurs réglages :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a3a632-3729-4467-891f-1b84350ef1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfe922-9dbe-4659-a8f0-386e8e0fb7e0",
   "metadata": {},
   "source": [
    "Et `.best_estimator_` affiche le modèle idéal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c686b1a-b308-4305-9bcd-a66d212e96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5efcb-429e-4c9d-9da0-d5cb0a7cd5db",
   "metadata": {},
   "source": [
    "Il est également possible de récupérer les scores de chaque combinaison, compulsés par la propriété `.cv_results_` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c25c2f9-032d-44a4-83d9-2ee359e35ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = grid_search.cv_results_\n",
    "\n",
    "for mean_test_score, params in zip(scores[\"mean_test_score\"], scores[\"params\"]):\n",
    "    print(f\"{mean_test_score:.3f} : {params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290a347-3c57-4203-b922-fada49ffc32c",
   "metadata": {},
   "source": [
    "## Réutiliser un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4c4092-303e-42b7-94f4-11986e47163a",
   "metadata": {},
   "source": [
    "De la compréhension du jeu de données par l’analyse des interactions entre les variables à l'évaluation de la perfomance des estimateurs grâce aux courbes d’apprentissage et de validation, toutes les étapes vers la régularisation du meilleur modèle demande du temps et, après avoir passé plusieurs heures à calculer les différentes combinaisons entre les hyperparamètres, nous souhaiterions sauvegarder notre modèle pour le réutiliser plus tard.\n",
    "\n",
    "Le module *Pickle* répond à ce besoin en sérialisant un objet Python en un flux d’octets grâce à la méthode `.dump()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4198e228-e3b7-44d1-a041-2d1d96ca4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode=\"wb\": binary mode\n",
    "pickle.dump(model, open(\"./data/model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ad6de-42bc-47f4-b719-f09478a17ee2",
   "metadata": {},
   "source": [
    "Et pour effectuer l’opération inverse de désérialiser un flux d’octets, il suffit d’appeler la méthode `.load()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34829642-eb77-411b-a2d2-af331a35dc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"./data/model.pkl\", \"rb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
