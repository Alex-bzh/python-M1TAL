{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4631cc4-ec66-4325-86e2-e6629f23ed6f",
   "metadata": {},
   "source": [
    "# Quelle chaleur !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f762fa1e-6c09-4ee4-ae35-8948fc79b854",
   "metadata": {},
   "source": [
    "Si vous avez toujours rêvé de vectoriser un épisode de la série *Kaamelott*, non seulement vous n’êtes pas très sain·e d’esprit mais en plus vous êtes au bon endroit. De la segmentation au calcul de similarités entre vecteurs en passant par la constitution d’un sac de mots (*bag of words*), vous mettrez en application quelques techniques essentielles en traitement du langage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a89779-c701-4f3d-8f23-6bc17c14f5ad",
   "metadata": {},
   "source": [
    "## Le texte de l’épisode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6220f551-9a69-4596-9953-874ab51f2852",
   "metadata": {},
   "source": [
    "Chargeons dans une variable `text` le contenu de l’épisode :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af45ef5e-fd87-4d48-b8ac-954868a90dee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../data/S01E01-heat.pos\") as f:\n",
    "    text = [ line.split('\\t')[1] for line in f.readlines() ]\n",
    "    text = \"\".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa60624-905f-4dd0-b576-2d5b39f12e31",
   "metadata": {},
   "source": [
    "Chaque ligne correpond à une réplique de l’épisode avec, pour chaque mot, des annotations pour renseigner son étiquette grammaticale et son lemme :\n",
    "\n",
    "```\n",
    "La/DET/le femelle/NC/femelle lièvre/NC/lièvre ,/PONCT/, c'/CLS/ce est/V/être la/DET/le hase/NC/hase ./PONCT/.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec2a2a2-80b5-4672-be1b-012f43e5a67a",
   "metadata": {},
   "source": [
    "## Préparation du sac de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28b34be-b4ba-4742-b6a1-a782ed5edea4",
   "metadata": {},
   "source": [
    "### Segmentation du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b184bf38-c483-4ee1-bbe4-7120534b6539",
   "metadata": {},
   "source": [
    "Transformez le texte en un ensemble de tuples `(lemma, pos)` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1aa27-774a-444a-9183-94dc532f2d83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e352b6-7caa-4eb7-abf4-102bfe447517",
   "metadata": {},
   "source": [
    "**Remarque :** nous proposons comme structure de données un ensemble parce que dans l’encodage *one-hot* nous n’avons pas besoin de garder trace de la fréquence des mots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd121b8-27d1-484e-af0c-465729360b89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Épurer la liste de tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f33ae1-6a02-4e7a-aa3d-c6d5ac45b53c",
   "metadata": {},
   "source": [
    "Plusieurs pistes communes pour réduire le volume du sac de mots :\n",
    "\n",
    "- retirer les signes de ponctuation ;\n",
    "- retirer les mots vides du français.\n",
    "\n",
    "**Remarque :** les annotations n’ayant pas été corrigées, certaines données sont aberrantes. Pour l’exercice, vous retirerez également toutes les occurrences de la forme `-`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34092732-20b1-43c0-843a-10ad7c4f7ba4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edaf810-7f8e-4a56-aa8d-f428dbaf824a",
   "metadata": {},
   "source": [
    "## Vectorisation de l’épisode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fd9aa-2b3f-49cd-85c0-8b79f21916b4",
   "metadata": {},
   "source": [
    "Avant toute chose, et pour des raisons d’efficacité, transformez la variable `tokens` en liste :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6274ee-b098-4187-9619-80d88c2ca792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ef59b-1f6b-4a7d-a828-4d40bf0de1c0",
   "metadata": {},
   "source": [
    "### Conversion du sac de mots en classificateurs binaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab4fcc-9f94-4956-8d8a-3c95eec6b55b",
   "metadata": {},
   "source": [
    "Pour la vectorisation, nous allons soumettre la liste des tuples à la méthode de l’encodage *one-hot* en mobilisant la classe `OneHotEncoder` de la librairie *Scikit-Learn* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2689c-b927-4042-a6ad-1de4d4caf38d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ea463-9185-4169-9575-86a564bb5cf9",
   "metadata": {},
   "source": [
    "Grâce à la méthode `.fit()`, nous ajustons ensuite notre encodeur avec les tokens :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543119e1-6962-4e7f-ab6b-9e903aacc1e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = encoder.fit(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a4c65-48d9-44c7-972b-2d6e0c9db209",
   "metadata": {},
   "source": [
    "L’encodeur est prêt. Notez que la propriété spéciale `.categories_` permet de retrouver la liste des différents classificateurs de notre corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab413e6-24d8-4861-b6b2-fbbf7f3ecfd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7bde7-2756-4802-b695-5b67b3ff9ff4",
   "metadata": {},
   "source": [
    "Et pour utiliser l’encodeur, il suffit de lui envoyer une structure de données similaire à celle avec laquelle il a été entraîné, à savoir ici une liste de tuples :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55d8d8e-ffa7-463a-892b-6ca015b85a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "encoder.transform(\n",
    "    [ ('ailleurs', 'ADV') ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26434695-f4a4-466b-89e2-701307f479c9",
   "metadata": {},
   "source": [
    "**Remarque :** le paramètre `sparse_output` transmis au constructeur de la classe `OneHotEncoder` a permis l’affichage de cette matrice creuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ad8c3d-c4f7-4a5c-b9a4-69c45f845a47",
   "metadata": {},
   "source": [
    "### Un dictionnaire de vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc84795-5c7c-410d-aba5-843c9760a81c",
   "metadata": {},
   "source": [
    "À partir de la liste des `(lemma, pos)` constituez un dictionnaire de vecteurs, de telle manière que l’instruction `vectors[('ailleurs', 'ADV')]` renvoie la matrice obtenue plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36c08dd-914e-4b3c-ae81-382b23cd7f1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f18bcb-cb77-4b1a-8b03-47ff7b7fb0cf",
   "metadata": {},
   "source": [
    "**Astuce :** pensez à la structure `defaultdict` à charger depuis le module `paquet`.\n",
    "\n",
    "Vérifiez que la création de votre dictionnaire a fonctionné :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344432e-aa99-41ec-a40a-fd125ef36f09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectors[('ailleurs', 'ADV')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad3713f-ee5a-4ee0-832e-9bc06ee3f14a",
   "metadata": {},
   "source": [
    "## Similarité entre vecteurs binaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a72aeb-82cd-4ef8-8197-bf5a4971e24f",
   "metadata": {},
   "source": [
    "Isolons trois vecteurs afin de les comparer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e035b00-adba-4f9b-95d8-2fa66060dd5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chevreuil = vectors[('chevreuil', 'NC')]\n",
    "animal = vectors[('animal', 'NC')]\n",
    "creuser = vectors[('creuser', 'V')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a7d8b0-43ac-47a4-ba64-d573ef8ef1f5",
   "metadata": {},
   "source": [
    "### L’indice de Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619616c-5662-4680-9d7b-d2fc7831d001",
   "metadata": {},
   "source": [
    "Étant en présence de vecteurs binaires, ou plus exactement de matrices de vecteurs binaires, l’indice Jaccard est tout indiqué pour calculer leur similarité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620bd03-6211-4112-b463-9fb9128e062d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "print(\n",
    "    f'L’indice de Jaccard pour \"chevreuil\" et \"animal\" est de : {jaccard_score(chevreuil[0], animal[0]):.3f}',\n",
    "    f'L’indice de Jaccard pour \"chevreuil\" et \"creuser\" est de : {jaccard_score(chevreuil[0], creuser[0]):.3f}',\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db269f34-472b-47d4-aff1-ba781ddfbdc8",
   "metadata": {},
   "source": [
    "### La similarité cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033bb523-fe9a-4bc0-9d80-7b57c676f5db",
   "metadata": {},
   "source": [
    "On aurait pu également opter pour la similarité cosinus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606349e2-716e-4a76-ae19-4e9c2872258f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\n",
    "    f'La similarité cosinus pour \"chevreuil\" et \"animal\" est de : {cosine_similarity(chevreuil, animal)}',\n",
    "    f'La similarité cosinus pour \"chevreuil\" et \"creuser\" est de : {cosine_similarity(chevreuil, creuser)}',\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
