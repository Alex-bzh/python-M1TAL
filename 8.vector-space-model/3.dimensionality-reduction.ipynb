{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c357dc92-be8d-4318-bbd1-c27a62a7be6b",
   "metadata": {},
   "source": [
    "# Introduction à la réduction de la dimensionnalité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29004b3-3f95-485e-8fc5-b163a201afc5",
   "metadata": {},
   "source": [
    "Notre parcours dans la définition du modèle vectoriel nous a conduit·e de la constitution d’un sac de mots par divers procédés à l’établissement d’une matrice d’occurrences. Nous avons d’ailleur quitté le chapitre précédent avec un double problème : d’une part la seule approche fréquentielle était incapable de rendre compte de l’importance relative d’un terme dans un document et encore moins dans un corpus ; d’autre part la constitution d’une matrice d’occurrences nous avait rapidement amené·e, en raison de la taille du vocabulaire commun à considérer, à évoluer dans des espaces en très haute dimension qui sont majoritairement remplis de vide.\n",
    "\n",
    "Dans ce chapitre, nous allons remédier au premier et dessiner l’ébauche d’une méthode pour projeter les documents dans un espace réduit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d17ddd-3385-42cb-af64-98e16239e357",
   "metadata": {},
   "source": [
    "## Évaluer l’importance d’un terme dans un document (TF-IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f3b737-77e4-43d8-a2bf-da53e551e0da",
   "metadata": {},
   "source": [
    "Nous l’avons vu précédemment, certains termes dans un corpus sont plus importants que d’autres pour caractériser un texte par rapport à un autre, et leur importance n’est souvent pas proportionnelle à leur fréquence. De là découle la nécessité de repérer les mots vides de sens, les *stopwords*, pour les retirer du sac de mots (BoW) qui le représente. Pour autant, la méthode BoW se contente d’une mesure fréquentielle sans établir de rapport d’importance entre les termes. La matrice d’occurrences reste ainsi assez pauvre pour rendre compte de sémantique.\n",
    "\n",
    "Une autre approche, largement répandue dans le traitement automatique du langage naturel, parvient à inférer, de l’analyse fréquentielle, une certaine valeur d’importance aux termes contenus dans le sac de mots. Cette approche repose sur deux principes : la fréquence du terme (TF) et la fréquence du terme dans le corpus (IDF) qui prêtent une signification à la rareté d’un terme.\n",
    "\n",
    "Sans parler de robustesse, la justification de cette approche repose sur la loi de Zipf qui prévoit que la fréquence d’un terme dans un texte est liée à son rang dans l’ordre des fréquences : le mot le plus fréquent apparaîtrait dix fois plus souvent que le dixième mot le plus fréquent, cent fois plus que le centième etc. En grande partie pour cette raison, la méthode TF-IDF ne souffre pas de la présence des mots vides dans le sac de mots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60acdf-3a82-407a-827e-237ee58a0a9e",
   "metadata": {},
   "source": [
    "### La fréquence du terme (TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed49f0-90d1-4cf5-959d-45042ace6ad8",
   "metadata": {},
   "source": [
    "De l’anglais *term frequency*, la fréquence du terme établit un rapport entre le nombre d’occurrences d’un mot ($w$) dans un document et le nombre total de mots dans ce document ($n$) :\n",
    "\n",
    "$$\n",
    "\\text{TF}(w, n) = \\frac{w}{n}\n",
    "$$\n",
    "\n",
    "Prenons un corpus constitué de trois textes :\n",
    "\n",
    "```txt\n",
    "(A) Le petit chat boit du lait. Le lait n’est pas bon pour les chats.\n",
    "(B) Les petits chiens boivent de l’eau. L’eau irait aussi aux chats.\n",
    "(C) À partir d’un moment, eau ou lait, ils peuvent bien boire ce qu’ils veulent.\n",
    "```\n",
    "\n",
    "La taille en mots du document *A* est de 15, quand elle est de 13 pour le document *B* et de 16 pour le document *C*. Intéressons-nous au mot *lait* ($1$) qui apparaît deux fois dans *A* et une fois dans *C*, mais jamais dans *B*. Ses fréquences seront :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{TF}_{1, A} &= \\frac{2}{15} = 0,1333 \\\\\n",
    "    \\text{TF}_{1, B} &= \\frac{0}{13} = 0 \\\\\n",
    "    \\text{TF}_{1, C} &= \\frac{1}{16} = 0,0625 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3395d10-d5e5-468a-a6e0-202c1d989332",
   "metadata": {},
   "source": [
    "### La fréquence inverse de document (IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04eb88d-c378-4802-b33e-ff77fb21864f",
   "metadata": {},
   "source": [
    "Quand la mesure TF s’attachait au terme dans un document, la mesure IDF (*inverse document frequency*) va s’intéresser à la présence du terme dans le corpus entier selon la relation suivante où $d$ représente le nombre de documents où le terme apparaît et $N$ le nombre total de documents :\n",
    "\n",
    "$$\n",
    "\\text{IDF}(d, N) = \\ln{\\frac{N}{d}}\n",
    "$$\n",
    "\n",
    "Dans notre exemple, la mesure IDF pour le mot *lait* vaut :\n",
    "\n",
    "$$\n",
    "\\text{IDF}_1 = \\ln{\\frac{3}{2}} \\approx 0.4055\n",
    "$$\n",
    "\n",
    "Le calcul du logarithme permet de pondérer le rapport entre $N$ et $d$ dans la mesure où, lors de l’obtention de TF, le résultat était situé dans un intervalle $[0, 1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccdd33d-8068-41c7-b91e-87833efcd2a9",
   "metadata": {},
   "source": [
    "### La mesure TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcdca72-25e9-4fd6-9ffd-7188af3fc954",
   "metadata": {},
   "source": [
    "Au final, la formule TF-IDF est un produit entre TF et IDF. Pour notre exemple avec le mot *lait* :\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "    \\text{TFIDF}_{1, A} &= \\frac{2}{15} \\cdot ln \\frac{3}{2} \\approx 0,0541 \\\\\n",
    "    \\text{TFIDF}_{1, B} &= \\frac{0}{13} \\cdot ln \\frac{3}{2} = 0 \\\\\n",
    "    \\text{TFIDF}_{1, C} &= \\frac{1}{16} \\cdot ln \\frac{3}{2} \\approx 0,0253 \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Au regard du mot *lait*, le document *A* apparaît ainsi comme plus pertinent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70c0a1-db3a-47d2-b779-4c302c369398",
   "metadata": {},
   "source": [
    "### Limitations du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f01a26-a2a5-4e59-935b-ace590b608d7",
   "metadata": {},
   "source": [
    "Quoique très largement utilisé pour sa facilité de mise en œuvre en dépit du coût en termes de calcul machine, la mesure TF-IDF souffre principalement de son incapacité à traiter la sémantique du terme.\n",
    "\n",
    "Gardons par ailleurs à l’esprit que la formule accordera mécaniquement davantage d’importance aux documents très volumineux, aussi faudra-t-il penser à les pénaliser ou bien à ne travailler que sur des corpus équilibrés."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
