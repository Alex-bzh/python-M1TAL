{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le Brown Corpus\n",
    "\n",
    "Le *Brown University Standard Corpus of Present-Day American English* est le premier grand corpus structuré et étiqueté de textes en anglais. Il a posé les bases pour l’étude scientifique de la fréquence et de la distribution des catégories de mots dans l’usage quotidien de la langue.\n",
    "\n",
    "Exemple de phrase étiquetée :\n",
    "\n",
    "```txt\n",
    "The/at Fulton/np-tl County/nn-tl Grand/jj-tl Jury/nn-tl said/vbd Friday/nr an/at investigation/nn of/in Atlanta's/np$ recent/jj primary/nn election/nn produced/vbd ``/`` no/at evidence/nn ''/'' that/cs any/dti irregularities/nns took/vbd place/nn ./.\n",
    "```\n",
    "\n",
    "Cet exercice vous amènera à manipuler les bases de NLTK en important un corpus catégorisé et étiqueté afin d’obtenir rapidement des statistiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparer les données\n",
    "\n",
    "Dans un premier temps, importez le corpus *Brown* qui fait partie du module `nltk.corpus` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le corpus est désormais manipulable à travers la variable `brown` qui, pour la petite histoire, est une instance de la classe `CategorizedTaggedCorpusReader`. Cela signifie simplement que le corpus est catégorisé.\n",
    "\n",
    "Essayez justement d’afficher les catégories grâce à la méthode `categories()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De ce corpus, nous ne retiendrons que deux catégories de textes : ceux humoristiques (`humor`) et ceux relatifs à la science-fiction (`science_fiction`).\n",
    "\n",
    "Nous savons déjà que la méthode `fileids()` permet de connaître les identifiants des textes du corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first ten file identifiers\n",
    "print(brown.fileids()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode accepte aussi un paramètre `categories` afin de limiter l’affichage à certaines catégories. Enregistrez dans une variable `files` les identifiants des textes relatifs aux catégories retenues plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "files = brown.fileids(categories=(\"humor\", \"science_fiction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupérer les étiquettes morpho-syntaxiques\n",
    "\n",
    "Les objets de la classe `CategorizedTaggedCorpusReader` héritent des méthodes de `TaggedCorpusReader` pour interroger le texte et afficher par exemple une liste de phrases constituées de mots étiquetés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(brown.tagged_sents('ca03'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour chacun des fichiers retenus, essayez d’afficher une simple liste de mots étiquetés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for file in files:\n",
    "    print(brown.tagged_words(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe à vrai dire une manière plus simple d’obtenir directement le résultat. Comme la méthode `tagged_words()` dispose d’un paramètre `categories`, on peut directement sauvegarder dans une variable `words` la liste des mots étiquetés appartenant aux catégories sélectionnées plus haut :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "words = brown.tagged_words(categories=(\"humor\", \"science_fiction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Et grâce à un paramètre `tagset` supplémentaire, nous pouvons convertir le jeu d’étiquettes en parties du discours au format universel (`universal`). Essayez de réaliser l’opération en réaffectant la variable `words` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "words = brown.tagged_words(categories=(\"humor\", \"science_fiction\"), tagset=\"universal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le jeu d’étiquettes universel en parties du discours est censée faciliter et normaliser la recherche scientifique en proposant douze étiquettes :\n",
    "\n",
    "|Étiquette|Catégorie|\n",
    "|-|-|\n",
    "|ADJ|adjective|\n",
    "|ADP|adposition|\n",
    "|ADV|adverb|\n",
    "|CONJ|conjunction|\n",
    "|DET|determiner, article|\n",
    "|NOUN|noun|\n",
    "|NUM|numeral|\n",
    "|PRT|particle|\n",
    "|PRON|pronoun|\n",
    "|VERB|verb|\n",
    "|.|punctuation marks|\n",
    "|X|other|\n",
    "\n",
    "**Crédits**\n",
    "\n",
    "Slav Petrov, Dipanjan Das, Ryan McDonald. – [\"A  Universal  Part-of-Speech  Tagset\"](http://www.petrovi.de/data/lrec.pdf) in *Proceedings of the Eighth International Conference on Language Resources and Evaluation* (LREC ’12). – Istanbul, Turquie, 21-27 mai 2012."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compter le nombre d’occurrences d’un élément\n",
    "\n",
    "Le module `collections` de Python propose une structure de données utile pour comptabiliser le nombre d’occurrences d’un élément : `Counter`\n",
    "\n",
    "Importez ce module :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Créons une liste aléatoire d’une centaine d’entiers naturels entre 0 et 9, transformons-là en objet `Counter` et demandons combien de fois apparaît le nombre 3 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module random\n",
    "from random import randint\n",
    "\n",
    "# A random list of integers between 0-9\n",
    "integers = [randint(0, 9) for n in range(0, 100)]\n",
    "# List into a Counter object\n",
    "integers = Counter(integers)\n",
    "# How many times the number \"3\" appears?\n",
    "print(integers[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La structure de données `Counter` ressemble à un dictionnaire où, pour chaque clé, correspond un nombre d’occurrences.\n",
    "\n",
    "Sur le même principe, créez une variable `tags` qui recense le nombre d’occurrences de chaque étiquette dans la liste des mots obtenus à partir du corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from collections import Counter\n",
    "\n",
    "tags = Counter(tag for word, tag in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, grâce à la méthode `most_common()`, affichez les cinq étiquettes les plus utilisées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "tags.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher une représentation graphique\n",
    "\n",
    "NLTK propose une classe `FreqDist` dans le module `probability` qui permet d’afficher rapidement un diagramme.\n",
    "\n",
    "Pour l’importer :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le modèle de l’instruction précédente, réaffectez la variable `tags` en créant une nouvelle instance de la classe `FreqDist` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "tags = FreqDist(tag for word, tag in words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il ne vous reste plus qu’à afficher une distribution de la fréquence d’apparition des étiquettes du corpus grâce à la méthode `plot()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "print(tags.plot())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
