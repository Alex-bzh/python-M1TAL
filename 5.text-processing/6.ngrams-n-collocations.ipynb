{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# *N*-grammes et collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Définitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### *N*-grammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "En traitement automatique du langage naturel, un *n*-gramme représente simplement une séquence de *n* mots. Les unigrammes, bigrammes et tétragrammes sont des cas spécifiques d’association de 1, 2 ou 3 mots quand, au-delà, on parle davantage de 4-grammes, 5-grammes etc. que de tétragrammes ou pentagrammes.\n",
    "\n",
    "Pour ne s'attacher qu’aux séquences de deux mots, on dénombre cinq bigrammes dans l’énoncé suivant :\n",
    "\n",
    "```txt\n",
    "(1) Le petit chat boit du lait.\n",
    "```\n",
    "\n",
    "Ces bigrammes sont :\n",
    "1. Le, petit\n",
    "2. petit, chat\n",
    "3. chat, boit\n",
    "4. boit, du\n",
    "5. du, lait\n",
    "\n",
    "Dans cette liste, tous les bigrammes n’ont pas le même poids. Quand *boit, du* ne veut pas dire grand chose, le bigramme *petit, chat* est bien plus significatif. C’est ici qu’entrent en jeu les collocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Skip-grams*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le terme de *skip-grams* désigne davantage une méthode de constitution de *n*-grammes qu’une véritable unité linguistique. Dans l’exemple (1), nous avons dénombré cinq bigrammes en tenant compte du contexte immédiat de chaque terme, excluant de fait l’association *chat*, *lait* qui pourtant semblait prometteuse. Pour l’intégrer, il suffit de déterminer au préalable une fenêtre contextuelle suffisante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Exprimée simplement, la collocation est le processus d’identification de deux ou plusieurs mots qui apparaissent fréquemment ensemble dans un énoncé.\n",
    "\n",
    "Elle permet de mettre en évidence, dans un énoncé, différents phénomènes linguistiques comme :\n",
    "- la lexicalisation (*au fur et à mesure*, *c’est-à-dire*)\n",
    "- les tics de langage (*pas de souci*, *ou pas*, *voilà voilà*)\n",
    "- les cooccurrences privilégiées (*courir vite*, *procès d’intention*, *soleil de plomb*)\n",
    "\n",
    "Une cooccurrence est qualifiée de collocation lorsqu’elle apparaît significativement plus souvent que ce que l’on attendrait si ses éléments étaient utilisés indépendamment.\n",
    "\n",
    "Par exemple, la cooccurrence *nuit noire* est qualifiée de collocation si sa probabilité conjointe $P(\\text{nuit} \\cap \\text{noire})$ est significativement supérieure au produit des probabilités individuelles $P(\\text{nuit}) \\cdot P(\\text{noire})$, c’est-à-dire à la probabilité attendue si les deux mots étaient utilisés indépendamment. Si dans un corpus fictif de 1 000 000 de mots, les mots *nuit* et *noire* apparaissent respectivement 10 000 et 8000 fois et que la cooccurrence *nuit noire* apparaît 1500 fois, alors :\n",
    "\n",
    "- $P(\\text{nuit}) = 0.01$\n",
    "- $P(\\text{noire}) = 0.008$\n",
    "- $P(\\text{nuit} \\cap \\text{noire}) = 0.0015$\n",
    "- $P(\\text{nuit}) \\cdot P(\\text{noire}) = 0.00008$\n",
    "\n",
    "La cooccurrence *nuit noire* est statistiquement plus probable (0,0015) que l’hypothèse d’indépendance (0,00008). Pour juger de sa significativité, il faudrait utiliser un test statistique, comme le $\\chi^2$, le *log-likelihood ratio* ou encore le *t-score*. Pour notre exemple, en appliquant la formule du *t-score* :\n",
    "\n",
    "$$\n",
    "t = \\dfrac{O - E}{\\sqrt{O}}\n",
    "$$\n",
    "\n",
    "Où :\n",
    "\n",
    "- *O* représente l’effectif observé ;\n",
    "- *E* vaut pour l’effectif attendu sous indépendance.\n",
    "\n",
    "Nous obtenons :\n",
    "\n",
    "$$\n",
    "E = \\dfrac{10000 \\times 8000}{1000000} = 80\n",
    "$$\n",
    "\n",
    "$$\n",
    "t = \\dfrac{1500 - 80}{\\sqrt{1500}} \\approx 36.65\n",
    "$$\n",
    "\n",
    "Le *t-score*, bien plus élevé que sous indépendance (0), révèle la significativité de la cooccurrence. À noter qu’en TAL, on considère souvent un seuil $t \\gt 2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lister des *n*-grammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La librairie NLTK met à disposition des méthodes pour lister facilement les *n*-grammes dans un énoncé. Ces méthodes ayant besoin en entrée d’une liste de mots, une étape préalable de tokenisation est indispensable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sent = \"Le petit chat boit du lait.\"\n",
    "words = word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pour lister les bigrammes, appeler la méthode `.bigrams()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "\n",
    "n_grams = bigrams(words)\n",
    "list(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Même principe pour les trigrammes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import trigrams\n",
    "\n",
    "n_grams = trigrams(words)\n",
    "list(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Et au-delà ? Une méthode `.ngrams()` avec un paramètre `n` pour définir le *n*-gramme souhaité. Par exemple pour des tétragrammes (4-grammes) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "n_grams = ngrams(words, 4)\n",
    "list(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Afin d’améliorer les résultats, supprimer les mots vides et la ponctuation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# regexp: selects only words\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# list stopwords\n",
    "stopwords = stopwords.words('french')\n",
    "\n",
    "# tokenization\n",
    "words = [\n",
    "    word.lower()\n",
    "    for word in tokenizer.tokenize(sent)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On ne sélectionne un bigramme que si aucun de ses éléments ne fait partie des mots vides :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "n_grams = bigrams(words)\n",
    "\n",
    "clean_bigrams = [\n",
    "    (w, c)\n",
    "    for w, c in n_grams\n",
    "    if w not in stopwords\n",
    "    and c not in stopwords\n",
    "]\n",
    "\n",
    "list(clean_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour relever des *skip-grams*, NLTK propose la fonction `skipgrams()` dans le module `util` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import skipgrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les paramètres `n` et `k` permettent de fixer respectivement le degré et la fenêtre contextuelle des *n*-grammes à recenser dans une liste de mots fournie en entrée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = skipgrams(words, n=2, k=3)\n",
    "\n",
    "clean_bigrams = [\n",
    "    (w, c)\n",
    "    for w, c in n_grams\n",
    "    if w not in stopwords\n",
    "    and c not in stopwords\n",
    "]\n",
    "\n",
    "clean_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Détecter des collocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La manière la plus rapide de détecter des collocations est d’utiliser la méthode `.collocations()` de la classe `Text` appliquée à un texte segmenté en mots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "from nltk.text import Text\n",
    "\n",
    "# loading the corpus\n",
    "corpus = PlaintextCorpusReader('./data', r'.*', encoding='utf8')\n",
    "\n",
    "# collocations in Salammbô\n",
    "salammbo = Text(corpus.words('salammbo.txt'))\n",
    "salammbo.collocations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les *n*-grammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les classes `BigramCollocationFinder` et `TrigramCollocationFinder`, permettent de dénicher dans un texte les 2-grammes et 3-grammes qui forment des collocations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En entrée, ces classes ont besoin qu’on leur fournisse une liste de mots :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import PlaintextCorpusReader\n",
    "\n",
    "# loading the corpus\n",
    "corpus = PlaintextCorpusReader('./data', r'.*', encoding='utf8')\n",
    "\n",
    "# list of words\n",
    "words = [\n",
    "    word.lower()\n",
    "    for word in corpus.words('salammbo.txt')\n",
    "]\n",
    "\n",
    "# 2-grams collocation finder\n",
    "collocations = BigramCollocationFinder.from_words(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Score des *n*-grammes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le package `nltk.metrics` offre des outils de mesure adaptés pour attribuer un score aux *n*-grammes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Parmi les outils de mesure à disposition, [la fonction de vraisemblance](https://fr.wikipedia.org/wiki/Rapport_de_vraisemblance) (*likelihood ratio*) est souvent la première à utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "likelihood = BigramAssocMeasures.likelihood_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Et pour obtenir ensuite les *n* bigrammes les plus fréquents, appeler la méthode `.nbest()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "collocations.nbest(likelihood, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La méthode `.score_ngrams()` permet de connaître le score attribué aux *n*-grammes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "collocations.score_ngrams(likelihood)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ce qui permet de limiter les résultats aux *n*-grammes qui dépassent un certain score :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "list(collocations.above_score(likelihood, 2000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "En plus de la fonction de vraisemblance, citons quelques autres outils de mesure :\n",
    "- la fréquence d’apparition\n",
    "- la [PMI](https://en.wikipedia.org/wiki/Pointwise_mutual_information) (*Pointwise mutual information*)\n",
    "- le [test de Student](https://fr.wikipedia.org/wiki/Test_de_Student)\n",
    "- le [test du $χ^2$](https://fr.wikipedia.org/wiki/Test_du_%CF%87%C2%B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Fréquence d’apparition : {collocations.nbest(BigramAssocMeasures.raw_freq, 5)}\")\n",
    "print(f\"PMI : {collocations.nbest(BigramAssocMeasures.pmi, 5)}\")\n",
    "print(f\"Test t : {collocations.nbest(BigramAssocMeasures.student_t, 5)}\")\n",
    "print(f\"Khi carré : {collocations.nbest(BigramAssocMeasures.chi_sq, 5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Filtrer les résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ne sont pas très probants : ponctuations et mots vides ressortent comme les plus fréquents. Une méthode `.apply_word_filter()` ajoute un filtre sur les mots sélectionnés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# list of stopwords\n",
    "stopwords = stopwords.words('french')\n",
    "\n",
    "# a filter calls a lambda function\n",
    "filter_stopwords = lambda w: w in stopwords\n",
    "collocations.apply_word_filter(filter_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Même si la situation s’améliore, les signes de ponctuation perturbent encore les résultats :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "collocations.nbest(likelihood, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "La solution consiste à modifier le filtre afin de supprimer les mots de un ou deux caractères :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "filter_stopwords = lambda w: w in stopwords or len(w) < 3\n",
    "collocations.apply_word_filter(filter_stopwords)\n",
    "collocations.nbest(likelihood, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Il est également possible d’imposer une fréquence d’apparition minimale à un *n*-gramme grâce à la méthode `apply_freq_filter()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "collocations.apply_freq_filter(3)\n",
    "collocations.nbest(likelihood, 5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
