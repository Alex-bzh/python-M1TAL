{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa672c4f-4c19-47ef-9afb-6fc6d57f9dfd",
   "metadata": {},
   "source": [
    "# Vectorisation avec Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b2f853-e559-4616-b8c9-f390595b2a31",
   "metadata": {},
   "source": [
    "## Opérations sur des vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef144c7-257d-4823-b816-31bed506e89b",
   "metadata": {},
   "source": [
    "Python fournit heureusement des outils pour effectuer les opérations sur les vecteurs. Parmi les librairies utiles, citons *math*, *Numpy*, *Scipy* et *Scikit-Learn*.\n",
    "\n",
    "Avant de les charger en fonction de nos besoins, reprenons quelques vecteurs vus dans le précédent calepin :\n",
    "\n",
    "$$\n",
    "\\vec{A} = \\begin{pmatrix}\n",
    "    3  \\\\\n",
    "    12 \\\\\n",
    "    9  \\\\\n",
    "    0\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\vec{B} = \\begin{pmatrix}\n",
    "    7  \\\\\n",
    "    32 \\\\\n",
    "    10\n",
    "\\end{pmatrix}\n",
    "\\hspace{2em}\n",
    "\\vec{C} = \\begin{pmatrix}\n",
    "    11 \\\\\n",
    "    4  \\\\\n",
    "    8\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d555e43-c455-4e4d-8c93-cc6edae5a6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [3, 12, 9, 0]\n",
    "B = [7, 32, 10]\n",
    "C = [11, 4, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae2c48-3317-498a-9ecd-a657727188d5",
   "metadata": {},
   "source": [
    "### Le produit scalaire de deux vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c6356-87ae-44be-9820-788f6adcf704",
   "metadata": {},
   "source": [
    "La méthode `.dot()` permet d’obtenir le produit de deux vecteurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9235d87-b58c-44b1-82e8-c97db789800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.dot(A, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4127cfb2-b65f-48fe-b172-b444ce2c24d2",
   "metadata": {},
   "source": [
    "### La norme d’un vecteur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52adfea-a667-4d87-b6d4-34bb4cebff78",
   "metadata": {},
   "source": [
    "Nous avions établi précédemment la norme du vecteur $\\vec{A}$ approximativement à $15,2971$. Vérifions notre calcul avec la fonction d’algèbre linéaire `norm()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b903a8-a201-41e7-baff-16de20091c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc76c93-c86e-4663-8f14-c99a7aaf24d8",
   "metadata": {},
   "source": [
    "### La distance entre deux vecteurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad49ce-b9e5-4f4c-8329-5da703faa602",
   "metadata": {},
   "source": [
    "La distance euclidienne entre deux vecteurs a cet avantage qu’elle peut se trouver dans un espace de n’importe quel dimension. L’opération revient à soustraire deux vecteurs puis à obtenir la norme de ce nouveau vecteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b4072-b3ab-4831-898b-8a69b7ca3a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array(C) - np.array(B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22098222-1a3f-4179-8a31-b2653361e52d",
   "metadata": {},
   "source": [
    "**Remarque :** notons que nous avons dû convertir explicitement nos variables `B` et `C`, de type `list` en tableaux *Numpy*. À titre anecdotique, le module `math` se passe de la conversion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c82011-a761-4c89-be16-169592385727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import dist\n",
    "\n",
    "dist(B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da01ce0b-cee6-4f69-b38a-a07f2fe0055c",
   "metadata": {},
   "source": [
    "## Métriques d’évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ad5585-5a0b-4a40-a07f-68a677d32a0e",
   "metadata": {},
   "source": [
    "### La similarité cosinus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87200a11-cd32-428e-90b2-5166f305daa7",
   "metadata": {},
   "source": [
    "Avec *Numpy*, il est nécessaire de déplier la formule :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efe4490-c097-4d7c-b8f0-2f2bb33c0add",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_BC = np.dot(B, C) / np.dot(np.linalg.norm(B), np.linalg.norm(C))\n",
    "\n",
    "print(f\"La similarité cosinus des vecteurs B et C est évaluée à {cos_BC * 100:.2f} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e97e7fd-e90b-491d-8902-905660aa40c6",
   "metadata": {},
   "source": [
    "Une fonction adéquate existe dans la librairie *Scikit-Learn*, `cosine_similarity`. Il convient toutefois de lui transmettre une matrice aux bonnes dimensions (nombre de vecteurs, nombre d’attributs). Dans notre exemple, la dimension serait (1, 3) parce que nous lui envoyons un vecteur constitué de trois composantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ac1d9-9258-4d63-9eb0-f23ba4a8bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_BC = cosine_similarity(\n",
    "    np.array(B).reshape(1, -1),\n",
    "    np.array(C).reshape(1, -1)\n",
    ")\n",
    "\n",
    "print(f\"La similarité cosinus des vecteurs B et C est évaluée à {cos_BC.ravel().tolist()[0] * 100:.2f} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e141b1a-c32e-422c-bf34-dc8ea116ac78",
   "metadata": {},
   "source": [
    "### L’indice de Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1663dac-27b3-4a52-b0ed-8fbae9173e5a",
   "metadata": {},
   "source": [
    "Une fois encore, *Scikit-Learn* permet d’obtenir directement la métrique en comparant deux vecteurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe407c-41d9-48bd-ae04-2157166effa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "A = [0, 0, 1, 1, 1]\n",
    "B = [1, 0, 1, 0, 0]\n",
    "\n",
    "print(f\"Les vecteurs A et B sont similaires à {jaccard_score(A, B) * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5d0906-7895-4c0b-a3df-0b26eb8c39ce",
   "metadata": {},
   "source": [
    "## Vectoriser un texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ceeae5-2201-44b2-bcd3-84a09910e81b",
   "metadata": {},
   "source": [
    "Considérons un corpus restreint de trois phrases :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65196ccf-514b-412c-9824-72e0efe952fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"Le petit chat boit du lait.\",\n",
    "    \"Le petit chien boit de l’eau.\",\n",
    "    \"La vache boit de l’eau mais ne boit pas de lait.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae44794-b45f-41b3-8b96-47ba481dcf0a",
   "metadata": {},
   "source": [
    "### L’approche fréquentielle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10217ff-e530-40cf-a21d-26914c71bbec",
   "metadata": {},
   "source": [
    "Le module *Scikit-Learn* dispose d’outils pour l’extraction de caractéristiques dans un texte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e299a-b9d2-4687-b1cf-f3996b678cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27baaf-3116-4958-861f-f286d90acc0f",
   "metadata": {},
   "source": [
    "Le résultat produit un vocabulaire, que l’on peut récupérer avec la méthode `.get_feature_names_out()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4232ef1-9ded-46e6-a6c7-bb0f26683d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f065fc5-5f25-4107-ad1d-c24c419075ed",
   "metadata": {},
   "source": [
    "La méthode `.toarray()` quant à elle permet de représenter la matrice creuse du corpus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2088a-a760-4468-9563-69ddf0c58dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6072dc-0dc9-49ea-b019-02e4a749cc4d",
   "metadata": {},
   "source": [
    "Associée à *Pandas*, il est possible de révéler le nom des colonnes afin de nous apprendre que dans la dernière phrase le mot *de* apparaît deux fois :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36d80cc-7c79-405b-b13c-fad9788becfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=X.toarray(),\n",
    "    columns=vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5f70c-4099-41e1-8127-fd0e2eca41b0",
   "metadata": {},
   "source": [
    "Il est également possible de transmettre directement un vocabulaire au constructeur plutôt que de lui laisser la charge de le construire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08010ed-f2bd-4f8b-bd7e-54ec12e68ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = ['boit', 'chat', 'chien', 'eau', 'lait', 'petit', 'vache']\n",
    "vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17d9480-0532-49d6-bd63-f80986240aa6",
   "metadata": {},
   "source": [
    "### L’encodage *one-hot*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415c201a-8320-4b93-b393-55dbc27b9aa1",
   "metadata": {},
   "source": [
    "Si l’on souhaite n’obtenir qu’un encodage *one-hot*, sans le décompte des occurrences du mot dans la phrase, il suffit de transformer la matrice de sortie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018dfec-89dc-4531-9585-6e800279097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda row: [ 0 if e == 0 else 1 for e in row ], X.toarray()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149d7d1c-9610-4795-ba07-2ab038c5d037",
   "metadata": {},
   "source": [
    "### La méthode TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c46b76-21e7-46b6-ab69-76cc265f35b8",
   "metadata": {},
   "source": [
    "À partir d’une matrice d’occurrences, obtenue par exemple avec le transformateur `CountVectorizer`, il est possible de calculer une matrice TF (*term frequency*) ou TF-IDF (*term frequency-inverse document frequency*). C’est le rôle du transformateur `TfidfTransformer` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c46d384-8fce-4902-8270-cf1581d61969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer()\n",
    "result = tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ce13f7-a0ab-4d53-9956-f35a11f7d1a7",
   "metadata": {},
   "source": [
    "Le résultat est une matrice creuse qu’il est possible d’afficher tel quel :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f37090-9fae-4405-8b1f-e274c9dd23c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f4451-872f-47ae-933a-7aac3c1ec768",
   "metadata": {},
   "source": [
    "Chaque ligne donne la mesure TF-IDF d’un mot dans un document. Prenons la ligne :\n",
    "\n",
    "```txt\n",
    "(1, 5)\t0.4804583972923858\n",
    "```\n",
    "\n",
    "Il faut comprendre ici que dans le document n°1, la mesure TF-IDF du terme n°5 est de 0,48046. Autrement dit, l’importance du terme *petit* est évaluée à 0,48046 dans la deuxième phrase de notre corpus.\n",
    "\n",
    "Il est à noter que le transformateur ne garde pas trace des caractéristiques apprises, juste de leurs indices :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef7d5b-0c82-447e-978f-30b9f591d8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df152b6e-da9a-47dd-af14-4d72ccc7842d",
   "metadata": {},
   "source": [
    "Pour les retrouver, il faut interroger la matrice d’occurrences :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c41bde-4bb3-4b6d-a14c-22ccd38285d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
