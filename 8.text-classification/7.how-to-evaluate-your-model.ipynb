{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4480e1ba-edcc-4dfd-bc9e-547e795be9f4",
   "metadata": {},
   "source": [
    "# Les méthodes d’évaluation d’un modèle prédictif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a87e26-5f2c-4b9b-ac75-0b45258184b1",
   "metadata": {},
   "source": [
    "Après des heures à paramétrer au mieux un modèle d’apprentissage avec la certitude d’avoir écarté les biais qui pourraient orienter les résultats – rappelons qu’un mauvais modèle peut fournir de très mauvais résultats avec une précision étonnante –, les premières prédictions sortent de la machine et nous souhaitons évaluer leur qualité afin de le passer en production ou non.\n",
    "\n",
    "Bien entendu, le cas présenté plus haut ne vaut que pour sa généralité ; dans la pratique, les méthodes d’évaluation sont présentes à chaque étape de la programmation d’un modèle si bien que presque aucun choix ne devrait être pris sans validation par une métrique ou une autre. Comme nous nous sommes concentrés sur deux types d’algorithmes, nous n’aborderons que les méthodes d’évaluation pour les tâches de régression et de classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1627dc-dd09-4814-b418-4b83cc091234",
   "metadata": {},
   "source": [
    "## Mesurer une erreur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1dab6e-842f-4271-99fd-b86703427985",
   "metadata": {},
   "source": [
    "Par métrique, on entend une façon d’évaluer la qualité d’une prédiction par mesure de la distance entre la réalité observée et la valeur calculée par un algorithme. Si l’on souhaite par exemple prédire la note d’un élève au prochain examen de français en se basant uniquement sur sa moyenne dans la matière – disons 12 –, l’algorithme de prédiction vaudra simplement :\n",
    "\n",
    "$$\\hat{y} = \\mu$$\n",
    "\n",
    "L’élève obtient finalement une note de 11. Pour mesurer l’erreur de la prédiction, il suffit de soustraire $\\hat{y}$ de $y$, soit un résultat de $-1$. Remarquons que si sa note avait été de 13, le résultat aurait été positif : $13 - 12 = 1$. Or, $-1$  et $+1$ étant situés à égales distances de la prédiction, ils représentent la même réalité géométrique. Dans les deux cas, l’erreur est réputée être de $1$. On utilise donc plutôt une formule impliquant les valeurs absolues :\n",
    "\n",
    "$$e = \\lvert y - \\hat{y}\\rvert$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b623b68-2633-4669-a07f-7b11e681c8ea",
   "metadata": {},
   "source": [
    "## Métriques pour les tâches de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab2a6dd-4409-4f72-9c92-48a8eac2a6da",
   "metadata": {},
   "source": [
    "Dans l’exemple de l’introduction, il s’agissait simplement de calculer l’erreur pour un couple unique prédiction/résultat. Qu’en serait-il si nous avions une série de prédictions et une série de résultats ? Plutôt que de calculer indépendamment les erreurs de chaque prédiction, nous préférerions obtenir une mesure de l’ensemble.\n",
    "\n",
    "Et pour corser le tout, il existe plusieurs métriques qui ne répondent pas tout à fait aux mêmes enjeux. Choisir la plus adaptée à la situation peut ainsi devenir une nécessité pour ajuster plus finement encore le modèle.\n",
    "\n",
    "Prenons le cas fictif de la pluviométrie au-dessus de la commune de Pont-Aven avec d’un côté les précipitations mesurées en millimètres pour les mois de janvier à mai 2022 et, de l’autre, des prédictions imaginaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17af8d-4bf5-4056-a2fd-cef33b2370b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# series\n",
    "series = {\n",
    "    \"months\": [\"Jan\", \"Feb\", \"March\", \"April\", \"May\"],\n",
    "    \"rainfall\": [70, 65, 55, 50, 9],\n",
    "    \"predictions\": [35, 60, 75, 45, 20]\n",
    "}\n",
    "# dataframe\n",
    "df = pd.DataFrame(series)\n",
    "\n",
    "# column 'months' still an id var, while two others are registered in a col 'Measure'\n",
    "df2 = pd.melt(df, id_vars=\"months\", var_name=\"Measure\", value_name=\"mm\")\n",
    "\n",
    "# graph\n",
    "_ = sns.lineplot(data=df2, x=\"months\", y=\"mm\", hue=\"Measure\", marker=\"o\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703dd24-a947-4099-b392-d9e05f95d9e2",
   "metadata": {},
   "source": [
    "### Le coefficient de détermination linéaire de Pearson ($R^2$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d95eff-6b04-4457-9766-0ebb8da80d76",
   "metadata": {},
   "source": [
    "Le $R^2$ est un score qui mesure de la qualité de la prédiction d’un modèle de régression linéaire en évaluant la variance d’une variable par rapport à une autre variable. Il est défini par la relation suivante pour un résultat généralement compris dans l’intervalle $[0,1]$ :\n",
    "\n",
    "$$R^2 = 1 - \\frac{\\sum_{i=1}^k(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^k(y_i - \\bar{y})^2}$$\n",
    "\n",
    "Son analyse est très intuitive mais elle implique deux critères :\n",
    "- le modèle est linéaire ;\n",
    "- une seule variable explicative est concernée.\n",
    "\n",
    "Un $R^2$ de 1.0 est un score parfait quand un score de 0.0 indiquerait que le modèle prédit toujours la valeur attendue (la moyenne). Un score négatif reste possible mais serait révélateur d’une erreur de méthodologie (données arbitrairement mauvaises).\n",
    "\n",
    "Dans le cas de notre exemple, la prédiction n’est clairement pas linéaire, aussi le calcul du $R^2$ ne devrait pas servir pour l’évaluation de notre modèle. À titre d’exercice, voyons ce qu’il donne en invoquant la fonction `r2_score()` du module `metrics` de *Scikit-learn* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f555455-f42a-4820-97f6-e47ae4877d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(df.rainfall, df.predictions)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71f038b-87db-45ba-a4db-b495d500856b",
   "metadata": {},
   "source": [
    "### L’erreur quadratique moyenne (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f7b56-3f10-4154-8dbd-a010cf5f7143",
   "metadata": {},
   "source": [
    "La MSE (*mean square error*) et sa cousine, la RMSE (*root mean square error*), sont les deux métriques les plus couramment utilisées en *machine learning*. La MSE calcule la moyenne des carrés des erreurs selon la formule :\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{k}\\sum_{i=0}^{k-1}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Comme entre en jeu un calcul au carré, la MSE pénalise plus fortement les grandes erreurs et, dans le même ordre d’idée, sera très sensible aux données aberrantes (*outliers*). La fonction dans *Scikit-learn* est `mean_squared_error()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d89b185-ef58-42c7-ae8d-35fbe2399eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(df.rainfall, df.predictions)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59c71a-d7df-4957-8864-55944ab2bbe0",
   "metadata": {},
   "source": [
    "### La racine de l’erreur quadratique moyenne (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07ce050-8012-49eb-882c-c9a6edc7b5c9",
   "metadata": {},
   "source": [
    "Plus facile à interpréter que la MSE, la RMSE (*root mean square error*) s’exprime dans l’unité de la variable à prédire en extrayant la racine carrée de la MSE :\n",
    "\n",
    "$$\\text{RMSE} = \\sqrt{ \\frac{1}{k}\\sum_{i=0}^{k-1}(y_i - \\hat{y}_i)^2 }$$\n",
    "\n",
    "À noter qu’elle souffre des mêmes limites que la MSE : une grande sensibilité aux *outliers* ainsi qu’une incidence forte sur les erreurs importantes. Pour la calculer avec *Scikit-learn*, il suffit de prendre la racine carrée de la MSE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0104c8-d3e5-4512-b37d-66f62a21163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# power of 0.5 = square root\n",
    "rmse = mse ** 0.5\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9083a903-fe8e-4ac6-a481-91e499837d39",
   "metadata": {},
   "source": [
    "### L’erreur absolue moyenne (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc387dfe-36f0-4ee6-b5bc-b3be99f4eba7",
   "metadata": {},
   "source": [
    "Quand les valeurs extrêmes d’un jeu de données sont quantitativement importantes, la RMSE pourrait conduire à des erreurs d’interprétation. Dans un tel cas de figure, la MAE (*mean absolute error*) peut lui être préférée : en calculant la moyenne de valeurs absolues, elle ne pénalise plus autant les grandes erreurs et se rend moins sensible aux données aberrantes. La formule de la MAE vaut ainsi :\n",
    "\n",
    "$$\\text{MAE} = \\frac{1}{k}\\sum_{i=0}^{k-1} \\lvert y_i - \\hat{y}_i\\rvert$$\n",
    "\n",
    "Dans *Scikit-learn*, la fonction `mean_absolute_error()` se charge du calcul :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b0a8c-b1d0-4201-bceb-60319204c0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(df.rainfall, df.predictions)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63c8134-16c7-4a70-9ede-b37cc0d48d56",
   "metadata": {},
   "source": [
    "## Métriques pour les tâches de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9608cdd3-4ab0-485a-bfed-24987699aa9d",
   "metadata": {},
   "source": [
    "### Classification binaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6461376-be1f-4428-999f-577fb70123d9",
   "metadata": {},
   "source": [
    "### Classification multi-étiquettes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
