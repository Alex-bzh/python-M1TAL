{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0818d992-55cf-47f4-8d01-918492b30d27",
   "metadata": {},
   "source": [
    "# Une droite de régression, à la main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0438fb-8232-41b4-ba68-17b933598925",
   "metadata": {},
   "source": [
    "Au cours de ce TD, vous apprendrez à calculer à la main une droite de régression linéaire grâce à la méthode des moindres carrés. Cela revient à résoudre l’équation réduite d’une droite de la forme $y = ax + b$.\n",
    "\n",
    "Pour la petite histoire, c’est en 1886 que le terme de régression apparaît pour la première fois, dans un article de Sir Francis Galton qu’il publie sous le titre de *Regression Towards Mediocrity in Hereditary Stature*. Dans cet article, il mettait en évidence que les enfants de personnes de grandes tailles avaient tendance à être plus petits qu’elles, et inversement, d’où l’idée d’une régression vers la médiocrité pour décrire un phénomène d’attraction vers la moyenne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50fd306-bf58-4420-9dec-7c7dcc9d640d",
   "metadata": {},
   "source": [
    "## Rappels sur l’équation réduite d’une droite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cf6e3-afca-48a6-9bf5-1868ae89d81b",
   "metadata": {},
   "source": [
    "Dans un plan orthonormé, une droite passe au minimum par deux points de coordonnées $(x1;y1)$ et $(x2;y2)$. Elle est caractérisée par une pente, son coefficient directeur, et par son ordonnée à l’origine, c’est-à-dire l’ordonnée de son point d’intersection avec l’axe des ordonnées. Dans la formule $y = ax + b$, le terme $a$ est le coefficient directeur et $b$ l’ordonnée à l’origine.\n",
    "\n",
    "Commencez par matérialiser une droite quelconque dans un plan en considérant les points de coordonnées $(2;3)$ et $(4;9)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875505e8-03a9-4f4b-b96d-6bb795c17b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "x = [2, 4]\n",
    "y = [3, 9]\n",
    "\n",
    "plt.xlim([0, 10])\n",
    "plt.ylim([0, 10])\n",
    "sns.regplot(x=x, y=y, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fc2318-2249-43ec-aeac-0a771068370e",
   "metadata": {},
   "source": [
    "### Le coefficient directeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ecb37e-07d3-4e93-9e14-4527c1153b09",
   "metadata": {},
   "source": [
    "Le coefficient directeur détermine la pente de la droite : s’il est positif, la droite monte ; s’il est négatif, la droite descend. Pour le calculer, la formule est :\n",
    "\n",
    "$$a = \\frac{\\Delta y}{\\Delta x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c080d51-adf5-48ba-8807-c83d6f751898",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (y[0] - y[1]) / (x[0] - x[1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3c006f-5dee-4707-b238-69174a38e5d7",
   "metadata": {},
   "source": [
    "### L’ordonnée à l’origine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7532a3a7-b6b5-4a02-95f9-10dfe3a89c93",
   "metadata": {},
   "source": [
    "Maintenant que vous connaissez $a$, il reste à calculer $b$, qui est l’orodnnée à l’origine. Or, vous savez que l’un des points de cette droite a pour coordonnées $(2;3)$, qui en est une solution. C’est-à-dire que lorsque $x$ vaut 2, alors $y$ vaut 3. Le droite qui vous occupe a donc pour équation :\n",
    "\n",
    "$$y = 3x + b$$\n",
    "\n",
    "D’où :\n",
    "\n",
    "$$3 = 3 \\times 2 + b$$\n",
    "$$b = -3 \\times 2 + 3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1dfb5-b374-44db-bc28-9d73b0218e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = -3 * 2 + 3\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e281231-eacd-4f44-b4ec-0466a6eafd79",
   "metadata": {},
   "source": [
    "Vous pouvez afficher cet autre point de coordonnées $(0;-3)$ sur la droite afin de vérifier graphiquement si la solution est correcte :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80677c8-7377-49f0-bdc9-79c8d47a7a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2, 4, 0]\n",
    "y = [3, 9, -3]\n",
    "\n",
    "plt.xlim([-1, 10])\n",
    "plt.ylim([-4, 10])\n",
    "sns.regplot(x=x, y=y, ci=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c7aec-b29e-4624-8db8-cb1c708e38cd",
   "metadata": {},
   "source": [
    "Vous pouvez conclure que l’équation réduite de la droite est : $y = 3x -3$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9963a81e-3a21-44f0-9e60-cc90d026e6d5",
   "metadata": {},
   "source": [
    "## Une droite de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c288211-a1de-47b2-81e9-df092e538a43",
   "metadata": {},
   "source": [
    "L’exemple introductif montrait comment calculer l’équation réduite d’une droite dont on connaît deux points. Le problème dans le cas de la régression, c’est que vous ne les connaissez pas, les points.\n",
    "\n",
    "Matérialisez concrètement la question avec le *dataset* sur les manchots en Antarctique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc441d-29e7-4082-8d62-1c114221a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/penguin-census.csv\")\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n",
    "sns.scatterplot(data=df, x=\"body_mass_g\", y=\"flipper_length_mm\", ax=ax1)\n",
    "sns.regplot(data=df, x=\"body_mass_g\", y=\"flipper_length_mm\", ci=None, ax=ax2)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d082d-092e-4f49-80fe-e2e2a675ed1c",
   "metadata": {},
   "source": [
    "Vous venez d’afficher deux nuages de points qui représentent deux caractéristiques des manchots : la masse en grammes sur l’axe des abscisses, et la longueur des nageoires en millimètres sur l’axe des ordonnées. Vous notez clairement une tendance : lorsque la masse d’un manchot augmente, la longueur de ses nageoires aussi. Ceci dit, la relation entre les deux caractéristiques n’est pas linéaire : aucun individu n’est identique et vous ne pouvez être sûr·es que, si un manchot pèse 500 g de plus qu’un autre, ses nageoires mesureront 10 mm de plus.\n",
    "\n",
    "Sur le graphique de droite, vous avez en plus affiché la droite de régression. Cette droite vous montre la tendance centrale qui minimise la somme des erreurs pour toutes les observations et qui vous permettrait en plus de prédire pour une certaine masse la longueur des nageoires d’un manchot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a484fa-a56f-4a8d-8664-287caa9d33d1",
   "metadata": {},
   "source": [
    "## La droite de régression des moindres carrés"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c393566-1ec5-43c0-8507-a45d6d127002",
   "metadata": {},
   "source": [
    "Lorsque vous prenez les coordonnées d’une observation, vous remarquez bien qu’elles sont éloignées de la droite. Il existe un décalage, que l’on appelle communément une erreur, et la droite de régression des moindres carrés est celle qui minimise la somme des carrés de toutes les erreurs. Le rapport s’établit au carré afin d’éviter les valeurs négatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a569e4-7b0e-45e5-abfc-98b8354cb827",
   "metadata": {},
   "source": [
    "### La formule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36359ada-5043-454b-8a73-7e2259188d22",
   "metadata": {},
   "source": [
    "L’équation réduite qui permet d’obtenir les coordonnées de tous les points de la droite et, partant, d’obtenir une prédiction de $\\hat{y}$ en fonction de $x$ respecte la forme $\\hat{y} = ax + b$. Deux étapes majeures pour la trouver, calculer d’abord le coefficient directeur $a$ puis l’ordonnée à l’origine $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d8477-8155-49a6-bd31-19477118ea73",
   "metadata": {},
   "source": [
    "### Calculer le coefficient directeur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f589553-4423-4cd1-9a9a-2dbdfc59616a",
   "metadata": {},
   "source": [
    "La résolution du coefficient directeur d’une droite des moindres carré est régi par la formule ci-dessous, où $n$ est le nombre des observations :\n",
    "\n",
    "$$a = \\frac{n\\sum xy - \\sum x \\sum y}{n \\sum x^2 - \\left(\\sum x\\right)^2}$$\n",
    "\n",
    "Commencez par définir un nouveau *data frame* avec l’ensemble des valeurs pour les caractéristiques *body_mass_g* et *flipper_length_mm*. Parmi toutes les manières de procéder, l’une d’elles mobilise la propriété `.loc[]` d’un *data frame* avec la liste des colonnes à conserver :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d434f2fd-1810-4ac3-a64b-f941848e43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "coords = df.loc[:,[\"body_mass_g\",\"flipper_length_mm\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20764880-2661-460b-b18f-51cc2355eff2",
   "metadata": {},
   "source": [
    "Dans un deuxième temps, utilisez une stratégie pour traiter les valeurs nulles et justifiez-la :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4644d-c540-4cb9-80dd-b813ffe41282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# only 2 na, drop them\n",
    "coords = coords.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5e7330-0f3a-4912-b7af-da7dfa2b5afa",
   "metadata": {},
   "source": [
    "Transformez maintenant le *data frame* en matrice *Numpy* grâce à la méthode `to_numpy()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2c50d-a77c-4d2b-bd01-9aeb7eaef317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "coords = coords.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c7af59-1dee-4ba5-8c12-a9deda079ca1",
   "metadata": {},
   "source": [
    "Chaque ligne du tableau est désormais un couple de coordonnées $x$ et $y$. Il vous reste à rajouter deux colonnes à la matrice pour :\n",
    "- le produit de $x$ et $y$ ;\n",
    "- le carré de $x$.\n",
    "\n",
    "Importez la librairie *Numpy* avec l’alias *np* et utilisez la méthode `column_stack()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da296c4-ac87-41d4-a5e4-40197a9656cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.column_stack((\n",
    "    coords,\n",
    "    coords[:, 0] * coords[:, 1],\n",
    "    coords[:, 0] ** 2\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408bbc73-1aa1-47eb-b309-f9312cb540c9",
   "metadata": {},
   "source": [
    "Il ne vous reste plus qu’à remplacer les inconnues de la formule par la somme des différents éléments de la matrice pour calculer le coefficient directeur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377309ab-61ae-440b-8db6-2e872b48fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def weight(d):\n",
    "    \"\"\"Return the weight of a straight line.\n",
    "\n",
    "    Argument:\n",
    "    d -- a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(d)\n",
    "    sum_x = sum(d[:, 0])\n",
    "    sum_y = sum(d[:, 1])\n",
    "    sum_xy = sum(d[:, 2])\n",
    "    sum_x2 = sum(d[:, 3])\n",
    "\n",
    "    return (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)\n",
    "\n",
    "a = weight(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a2d022-880c-4363-a42c-6862ff29d6e3",
   "metadata": {},
   "source": [
    "### Calculer l’ordonnée à l’origine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c20a34-3e61-40a3-9e61-8bcf9b8feb8f",
   "metadata": {},
   "source": [
    "La formule de résolution de l’ordonnée à l’origine fait appel au coefficient directeur et aux moyennes des valeurs de $x$ et de $y$ :\n",
    "\n",
    "$$b = \\bar{y} - a\\bar{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3898bca-d5d9-4dcf-a269-7bac9ff1e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def intercept(a, d):\n",
    "    \"\"\"Intercept of a straight line.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- weight\n",
    "    d -- a numpy array\n",
    "    \"\"\"\n",
    "\n",
    "    avg_y = np.average(d[:, 1])\n",
    "    avg_x = np.average(d[:, 0])\n",
    "    \n",
    "    return avg_y - (a * avg_x)\n",
    "\n",
    "b = intercept(a, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190da09-edbb-4e61-9b72-91622926f4c5",
   "metadata": {},
   "source": [
    "### Afficher le graphique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bb0734-910f-41c8-ab7f-a2f1029f4af6",
   "metadata": {},
   "source": [
    "Vous avez maintenant tous les éléments en main pour mettre en place le graphique. Plus que quelques étapes avant de voir le résultat s’afficher.\n",
    "\n",
    "Définissez tout d’abord une fonction `F(*, x, a, b)` qui renvoie l’équation réduite d’une droite :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7643ad-dfe9-48cc-8b42-0ee19df24b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "def F(*, x, a, b):\n",
    "    \"\"\"Solution to the standard form equation\n",
    "    of a straight line.\n",
    "    \n",
    "    Keyword-only arguments:\n",
    "    x -- value of x\n",
    "    a -- weight\n",
    "    b -- intercept\n",
    "    \"\"\"\n",
    "    return a * x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a5028-65be-4334-9a11-1c5bf14642c4",
   "metadata": {},
   "source": [
    "Instanciez deux variables nommées `X` et `Y` pour recevoir respectivement tous les $x$ et tous les $y$ de la matrice *Numpy* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af0aea-562d-4c1f-8785-c9b04a1cd1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "X = data[:, 0]\n",
    "Y = data[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb6250-7393-4fb8-bcef-84f4726fb957",
   "metadata": {},
   "source": [
    "Et constituez une matrice `Y_pred` pour les prédictions à partir des valeurs contenues dans `X`. Pour rappel, la fonction définie plus haut permet d’effectuer des prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eca1e9-ab03-4a04-945c-ed1029bedd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "Y_pred = [ F(x=x, a=a, b=b) for x in X ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a1e9dd-3dc7-4ce6-9a9f-79a6078cbf80",
   "metadata": {},
   "source": [
    "Exécutez le code ci-dessous pour voir le graphique s’afficher :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489671d0-e90f-4265-9507-9fbd6478c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.subplots()\n",
    "\n",
    "ax = sns.lineplot(x=X, y=Y_pred, color=\"fuchsia\")\n",
    "ax = sns.scatterplot(x=X, y=Y, color=\"seagreen\")\n",
    "\n",
    "ax.set(xlabel=\"Body mass (g)\", ylabel=\"Flipper length (mm)\")\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09144505-4a7d-4628-9a8d-690056af1446",
   "metadata": {},
   "source": [
    "## Résolution avec l’équation normale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7862125-722a-42ba-ac82-ff687b2a5945",
   "metadata": {},
   "source": [
    "Il existe une méthode plus rapide et tout aussi efficace pour calculer le coefficient directeur et l’ordonnée à l’origine d’une droite de régression, l’équation normale :\n",
    "\n",
    "$$\\hat{\\theta} = \\left(X^TX\\right)^{-1}X^Ty$$\n",
    "\n",
    "Pour résoudre cette équation, nous avons besoin de connaître trois éléments pour mettre en place la formule :\n",
    "- La fonction `np.linalg.inv()` pour obtenir l’inverse d’une matrice ;\n",
    "- la syntaxe `X.T` pour la transposée d’une matrice ;\n",
    "- et la méthode `dot()` pour le produit matriciel.\n",
    "\n",
    "Essayons simplement de traduire la formule telle quelle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2b7d0-7190-4738-a248-36949f000b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy as matrices\n",
    "X = np.c_[coords[:, 0]]\n",
    "y = np.c_[coords[:, 1]]\n",
    "\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n",
    "theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fd6467-d4b2-4301-967b-e6e51f7e4b43",
   "metadata": {},
   "source": [
    "Une seule valeur est contenue dans `theta` alors qu’on nous en avait promis deux : le coefficient directeur et l’ordonnée à l’origine. Pour comprendre le problème, il faut bien se représenter la manière dont s’effectuent à la fois la transposition d’une matrice et le produit matriciel.\n",
    "\n",
    "Considérons deux points de coordonnées $(3;2)$ et $(5;1)$ que nous répartissons dans deux matrices, $m$ pour les coordonnées sur l’axe des abscisses et $n$ pour celles sur l’axe des ordonnées, toutes deux de dimensions $(2, 1)$ :\n",
    "\n",
    "$$ m =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3 \\\\\n",
    "        5 \\\\\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "$$ n =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        2 \\\\\n",
    "        1 \\\\\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "La transposée de $m$ devient une matrice de dimensions $(1, 2)$ :\n",
    "\n",
    "$$\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3 \\\\\n",
    "        5 \\\\\n",
    "    \\end{array} } \\right]^\\top =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3 & 5\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "Et le résultat du produit matriciel entre les deux renvoie une matrice carrée de dimensions $(1, 1)$ :\n",
    "\n",
    "$$\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3 & 5\n",
    "    \\end{array} } \\right] \\times\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3 \\\\\n",
    "        5 \\\\\n",
    "    \\end{array} } \\right] =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        (3 \\times 3) + (5 \\times 5)\n",
    "    \\end{array} } \\right] =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        34\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "Or, nous aurions besoin d’une matrice de dimensions $(2,2)$ au moment d’effectuer le produit matriciel avec $n$, et ce afin d’obtenir `a` et `b`. Il nous manque clairement une dimension. D’autant plus que, à bien réfléchir, dans la géométrie euclidienne, on a besoin de deux points pour tracer une droite. Comment faire pour calculer le coefficient directeur et l’ordonnée à l’origine d’une droite qui n’en comporte qu’un seul ?\n",
    "\n",
    "Poursuivons l’exemple en calculant maintenant l’inverse de la matrice obtenue précédemment :\n",
    "\n",
    "$$\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        34\n",
    "    \\end{array} } \\right]^{-1} =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        0.02941176\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "Multiplions à présent cette matrice $(1, 1)$ avec la transposée de $m$ pour obtenir une matrice de dimensions $(1, 2)$ :\n",
    "\n",
    "$$\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        0.02941176\n",
    "    \\end{array} } \\right] \\times\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3 & 5\n",
    "    \\end{array} } \\right] =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        0.08823529 & 0.14705882\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "Dernière étape de notre développement, le produit avec $n$ :\n",
    "\n",
    "$$\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        0.08823529 & 0.14705882\n",
    "    \\end{array} } \\right] \\times\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        2 \\\\\n",
    "        1 \\\\\n",
    "    \\end{array} } \\right] =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        (0.08823529 \\times 2) + (0.14705882 \\times 1)\n",
    "    \\end{array} } \\right] =\n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        0.32352941\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "La solution consiste à rajouter une dimension à $m$, de telle manière que le produit n’en soit pas affecté. On en revient toujous à l’équation réduite d’une droite $y = \\theta x$ où $x$ est notre matrice $m$ et $\\theta$ la matrice qui devra contenir $a$ et $b$. Or, dans notre exemple, $\\theta$ ne pourra être constitué que d’un élément, ce qui ne nous permettra pas de retrouver la formule canonique $y = ax + b$, mais seulement $y = ax$ avec en prime une fausse estimation de $x$. Pour que le produit matriciel fonctionne, nous allons fixer la nouvelle dimension de notre matrice initiale $m$ à $1$ pour obtenir :\n",
    "\n",
    "$$y = ax + b \\times 1$$\n",
    "\n",
    "D’un point de vue mathématique, la matrice $m^\\prime$ prendra l’aspect suivant :\n",
    "\n",
    "$$\n",
    "    m^\\prime = \n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        1 & 3 \\\\\n",
    "        1 & 5 \\\\\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "Ce qui, après traduction de la formule donnera en sortie :\n",
    "\n",
    "$$\n",
    "    \\theta = \n",
    "    \\left[ {\\begin{array}{cc}\n",
    "        3.5 \\\\\n",
    "        -0.5 \\\\\n",
    "    \\end{array} } \\right]\n",
    "$$\n",
    "\n",
    "De là, nous pourrons établir l’équation réduite de la droite :\n",
    "\n",
    "$$y = -0.5x + 3.5$$\n",
    "\n",
    "Reprenons nos données et voyons comment calculer tout cela avec Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe1a6ae-af1a-4670-8afe-fdddd722b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.c_[\n",
    "    # x0 = 1\n",
    "    np.ones(coords[:, 0].shape),\n",
    "    # x1 = x\n",
    "    coords[:, 0]\n",
    "]\n",
    "y = np.c_[coords[:, 1]]\n",
    "\n",
    "theta = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59b29c9-7001-4847-8d98-d252101c4031",
   "metadata": {},
   "source": [
    "Vérifions que les résultats coïncident bien avec ceux de la méthode des moindres carrés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4baa22c-6a4f-4bb2-a03f-b65d2eade47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    theta[0].round(4) == b.round(4),\n",
    "    theta[1].round(4) == a.round(4),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a8b4f-fb72-42ea-a894-81ec761a8b24",
   "metadata": {},
   "source": [
    "## Méthode de la descente de gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60e6a0d-dc55-49e8-b7ea-9b8b6e3e7f42",
   "metadata": {},
   "source": [
    "Une autre méthode, adaptable à des problèmes plus complexes que celui qui nous concerne, consiste à effectuer la recherche des meilleurs paramètres par tâtonnement en commençant par des valeurs aléatoires. Les paramètres s’ajustent au fur et à mesure que la fonction de coût, généralement l’erreur quadratique moyenne (MSE), diminue.\n",
    "\n",
    "On appelle cette méthode la descente de gradient. Sans rentrer dans les détails, elle nécessite trois paramètres :\n",
    "- des valeurs aléatoires pour initialiser $\\theta$ ($a$ et $b$) ;\n",
    "- un nombre d’itérations suffisant pour converger ;\n",
    "- un taux d’apprentissage, noté $\\eta$, qui ne soit ni trop faible, afin d’éviter de ralentir l’entraînement, ni trop élevé, afin d’éviter le sur-entraînement.\n",
    "\n",
    "En plus de ces paramètres, la descente de gradient ne peut se calculer que sur des **données standardisées**. Effectuons une copie propre de `X` et `y`, puis utilisons la classe `StandardScaler` pour les centrer-réduire :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1da40-4082-4f07-a1ec-f48bf1f7c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = np.c_[coords[:, 0]]\n",
    "y = np.c_[coords[:, 1]]\n",
    "\n",
    "# scaler: Z score normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scaling\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y_scaled = scaler.fit_transform(y)\n",
    "\n",
    "# x0 = 1\n",
    "X_scaled = np.c_[np.ones(X.shape), X_scaled]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd3cd61-3490-48a4-bf22-535c05e52ef7",
   "metadata": {},
   "source": [
    "Fournissons des valeurs aux paramètres obligatoires de la descente de gradient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafab515-30f4-4257-9a58-0ac4a21e4784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "eta = 0.1\n",
    "# number of iterations\n",
    "n_steps = 1000\n",
    "# rows in X\n",
    "m = len(X_scaled)\n",
    "# random values to initialize theta\n",
    "theta = np.random.randn(2,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ad41e-6f93-45d0-9847-a2da02c501a7",
   "metadata": {},
   "source": [
    "Appliquons maintenant la formule :\n",
    "\n",
    "$$\\theta = \\theta - \\eta \\nabla_\\theta \\text{MSE}(\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75249a44-fe4e-425c-8e07-848c2250ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each step\n",
    "for step in range(n_steps):\n",
    "    # the gradients\n",
    "    gradients = 2/m * X_scaled.T.dot(X_scaled.dot(theta) - y_scaled)\n",
    "    # theta\n",
    "    theta = theta - eta * gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c64872-26c7-44bb-a24e-2217af5adeb8",
   "metadata": {},
   "source": [
    "Comme dans la méthode de résolution avec l’équation normale les données n’étaient pas à l’échelle, standardisons-les avant de comparer les valeurs de `theta` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c3d44a-ce6a-4cdf-9e09-ce4242f585ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_norm = np.linalg.inv(X_scaled.T.dot(X_scaled)).dot(X_scaled.T).dot(y_scaled)\n",
    "\n",
    "print(\n",
    "    theta[0].round(4) == theta_norm[0].round(4),\n",
    "    theta[1].round(4) == theta_norm[1].round(4),\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bebc5ed-f883-4dc4-a84b-c9c6369eaa77",
   "metadata": {},
   "source": [
    "## Établir une mesure de la performance du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f75f9f-5076-48de-8f19-4c43137e06c6",
   "metadata": {},
   "source": [
    "Si la droite obtenue par un calcul manuel correspond plus ou moins au graphique attendu, il reste à évaluer la performance du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e97db1b-df80-468e-83e0-ac3572703854",
   "metadata": {},
   "source": [
    "### La racine de l’erreur quadratique moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bdff4a-db1e-460c-b0fb-4c0bc6d13715",
   "metadata": {},
   "source": [
    "Calculez tout d’abord la RMSE (*root-mean-square error*) de votre modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b972f1-6c16-428e-9ffc-7bf56827c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(Y, Y_pred)\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "print(f\"RMSE du modèle : {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff25569-9d9b-43c5-a388-ac280d0edb2d",
   "metadata": {},
   "source": [
    "### L’erreur absolue moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6628f88-1cfc-4973-8bdb-dff399487388",
   "metadata": {},
   "source": [
    "Une autre mesure de la performance est la MAE (*mean absolute error*), qui permet d’estimer, dans l’unité de la variable cible, l’erreur moyenne pour une prédiction donnée. Chargez la fonction `mean_absolute_error()` du module `sklearn.metrics`, puis exécutez-la avec comme paramètres `Y` et `Y_pred` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120ada22-e247-496b-8588-e14bb824c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(Y, Y_pred)\n",
    "\n",
    "print(f\"MAE du modèle : {mae:.2f} mm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
