{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40da97c-5e87-4da6-9f37-b6bfc7fe9e71",
   "metadata": {},
   "source": [
    "# Classification de textes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99491bfc-73e6-42a4-ac01-a256ccf4e377",
   "metadata": {},
   "source": [
    "La classification de textes fait partie des applications courantes du traitement automatique du langage et, pourtant, il n’existe pas encore de méthode infaillible de parvenir à un résultat qui donne entière satisfaction, pas plus que de recette applicable à toutes les tâches.\n",
    "\n",
    "L’objectif, extrêmement simple, continue de poser des difficultés aux programmes informatiques. Il s’agit, pour résumer, d'attribuer le plus justement une étiquette à un texte. L’email reçu est-il un spam ou un message légitime ? Cette pièce a-t-elle été écrite par Molière ou par Corneille ? La dernière critique postée sur mon blog est-elle positive ou négative ? Aux exemples de classification binaire se rajoutent des cas de classification multi-classes (à quel genre rattacher ce roman ?) et de classification multi-étiquettes (identifier par exemple qu’un message contient à la fois une réclamation pour le service client et une question pour le service technique).\n",
    "\n",
    "Il s’agira, dans ce calepin, de reconnaître parmi un corpus de tweets ceux qui traitent de catastrophes réelles. Commençons par charger les bibliothèques nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f67f993-e67c-40ec-a01b-e94cfb5cd001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5242d4-4c2e-4e75-bf76-ef8836317b65",
   "metadata": {},
   "source": [
    "## Présentation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13d3cf-0b41-453f-85cb-82d90cf6a87a",
   "metadata": {},
   "source": [
    "Les données sont issues d’une compétition ouverte sur la plateforme *Kaggle* et servant d’introduction aux tâches de prédiction : [*Natural Language Processing with Disaster Tweets*](https://www.kaggle.com/c/nlp-getting-started/)\n",
    "\n",
    "Le jeu de données initial est constitué de deux fichiers pour l’entraînement (7503 observations) et l’évaluation (3243 observations). Nous n’utiliserons ici que le premier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec3851b-e5e3-451d-9bbb-e109102b20df",
   "metadata": {},
   "source": [
    "### Contenu du jeu d’entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928c393-c17b-4dae-bd6b-041c8baf1a4d",
   "metadata": {},
   "source": [
    "Le jeu d’entraînement est constitué de 7613 observations décrites par cinq variables :\n",
    "\n",
    "|Variable|Type de donnée|Description|\n",
    "|:-:|:-:|-|\n",
    "|`id`|entier naturel|Identifiant de l’observation|\n",
    "|`keyword`|caractères|Mot-clé parmi une liste contrôlée pour qualifier le tweet|\n",
    "|`location`|caractères|Provenance du tweet|\n",
    "|`text`|caractères|Texte du tweet|\n",
    "|`target`|entier naturel|Facteur numérique à deux niveaux pour identifier les tweets qui traitent d’une catastrophe (1) et les autres (2) |\n",
    "\n",
    "> Addison Howard, devrishi, Phil Culliton, Yufeng Guo. (2019). [*Natural Language Processing with Disaster Tweets*](https://www.kaggle.com/c/nlp-getting-started/). Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae307a-5cc2-49c5-80ce-d567d1cb01c9",
   "metadata": {},
   "source": [
    "### Charger les données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94f4556-69ce-42f3-95fe-4124be9d93ea",
   "metadata": {},
   "source": [
    "À l’aide de *Pandas*, chargeons les données dans un *data frame* en ne reprenant que les variables `id`, `text` et `target` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1612cac-fcda-42e5-b356-ffdb88578633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/disasters.csv', usecols=['text', 'target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180e695a-d292-4b7c-921b-09e6f5e76561",
   "metadata": {},
   "source": [
    "Vérifions que l’importation s’est bien déroulée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e069f93-2137-4473-a359-aa088b1a421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353953c-0736-4eef-8ccb-014cb627da86",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant définir nos caractéristiques ainsi que la variable cible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04484a69-fe3a-4b51-b396-84d9a4b81fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b696ac5-4b94-4df5-811b-dd84587a4b57",
   "metadata": {},
   "source": [
    "## Vectoriser le texte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd373114-9e0e-447b-8696-7721d99913ef",
   "metadata": {},
   "source": [
    "Tous les algorithmes d’apprentissage reposant sur des données numériques, il convient de choisir une méthode de vectorisation du texte. Nous optons pour une représentation des tweets sous forme de matrice TF-IDF :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72c9ec-1d9b-448a-afb8-ed87b45bd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efc94e-e3dc-404f-90da-5c0b72db3dcf",
   "metadata": {},
   "source": [
    "Regardons les mesures TF-IDF du premier tweet :\n",
    "\n",
    "> &laquo; Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all &raquo;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a3783e-8188-40e1-a5c0-df842104a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = 0\n",
    "print(tfidf[tweet_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb49802-c44f-49aa-ae5d-5a349810f7d4",
   "metadata": {},
   "source": [
    "Et affichons-les dans un *data frame* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a62ecef-1a4d-452b-abd0-d5d1cf516b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features names\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# remove axe of length one\n",
    "arr = np.squeeze(tfidf[tweet_id].toarray())\n",
    "\n",
    "# how many non-0 tf-idf?\n",
    "nb_ids = len(arr[arr != 0])\n",
    "\n",
    "# ids of these elements\n",
    "ids = np.argsort(arr)[::-1][:nb_ids]\n",
    "\n",
    "# retrieve feature name associated to tf-idf score\n",
    "tweet_tfidf = [ (features[i], arr[i]) for i in ids ]\n",
    "\n",
    "# vizualisation\n",
    "pd.DataFrame(data=tweet_tfidf, columns=['feature', 'tfidf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33049418-4a12-4015-9e4b-02ec98f001c5",
   "metadata": {},
   "source": [
    "## Réduire la dimensionnalité"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae302c-119b-4504-9e7d-46d9b92f0ddf",
   "metadata": {},
   "source": [
    "La matrice obtenue est de taille respectable. D’un jeu de données de dimension $(7613, 2)$, nous sommes arrivés à une matrice $(7613, 21637)$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8e1a50-11ad-46c0-a2c9-638c1325dd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Dimensions du dataframe : {df.shape}\",\n",
    "    f\"Dimensions de la matrice TF-IDF : {tfidf.shape}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6cd121-eab5-4b0f-9ca3-c680f4d59693",
   "metadata": {},
   "source": [
    "La seule technique que nous connaissons pour réduire le nombre de dimensions est l’analyse en composantes principales. Nos données ne se prêtent malheureusement pas à l’exercice : une ACP requiert des données centrées alors qu’il n’est pas possible de centrer une matrice creuse.\n",
    "\n",
    "Nous devons opter pour une autre technique de réduction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cf5e00-fa61-422d-91d7-e1f47a5ffcb1",
   "metadata": {},
   "source": [
    "### L’analyse sémantique latente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bddc487a-27b5-43ee-ac6d-6ed111433491",
   "metadata": {},
   "source": [
    "L’analyse sémantique latente (ou LSA en anglais pour *Latent Semantic Analysis*) s’attache à découvrir des concepts qui relient les documents et les termes qu’ils contiennent. Elle se fonde sur une matrice des occurrences pour effectuer ensuite une pondération TF-IDF et calculer une nouvelle matrice, par une décomposition en valeurs singulières (ou SVD en anglais pour *Singular Value Decomposition*), qui en sera une approximation mais de dimension inférieure.\n",
    "\n",
    "Dans *Scikit-Learn*, le transformateur `TruncatedSVD()` se charge de ces aspects :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2cb1a5-c9eb-4522-b79a-ac037dfc18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# singular value decomposition in 500 components\n",
    "svd = TruncatedSVD(n_components=500, random_state=42)\n",
    "\n",
    "# transform tfidf into lsa\n",
    "lsa = svd.fit_transform(tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26575b-15c1-4bcd-8d1a-d540bc19b237",
   "metadata": {},
   "source": [
    "Nous avons volontairement choisi un nombre important de composants afin d’afficher un diagramme d’éboulis en se reposant sur les attributs `.explained_variance_` et `.components_` qui enregistrent respectivement les valeurs singulières et les vecteurs singuliers.\n",
    "\n",
    "**Attention !** Contrairement à la PCA, les valeurs singulières ne sont pas triées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23050eba-ce27-4cb9-83f3-dbb78d660604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of indices when singular values are sorted in reverse order\n",
    "idx = svd.explained_variance_.argsort()[::-1]\n",
    "\n",
    "# sorting\n",
    "svd.explained_variance_ = svd.explained_variance_[idx]\n",
    "svd.components_ = svd.components_[:, idx]\n",
    "\n",
    "# scree plot\n",
    "_ = sns.lineplot(x=range(1, len(svd.components_) + 1), y=svd.explained_variance_)\n",
    "plt.title(\"Diagramme d’éboulis\")\n",
    "plt.xlabel(\"Numéro de la composante\")\n",
    "plt.ylabel(\"Explication de la variance\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e4f69a-0a6c-4e05-9db2-211112c9bf6b",
   "metadata": {},
   "source": [
    "Sur le graphique, nous remarquons que la performance baisse autour de 60-70 composantes. Qu’en est-il si nous souhaitons conserver un taux de 70 % de la variance ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a997c6-7792-477b-a496-11dbde406294",
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = 0\n",
    "nb_c = 0\n",
    "for n, singular_value in enumerate(svd.explained_variance_):\n",
    "    variance += singular_value / sum(svd.explained_variance_)\n",
    "    nb_c += 1\n",
    "    if variance > .7: break\n",
    "\n",
    "print(f\"Les {nb_c} premières composantes expliquent {variance:.2%} de la variance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee4aa01-669a-4a8e-b013-42efbd606baa",
   "metadata": {},
   "source": [
    "Conservons les 241 premières composantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7c21c-2f9d-4c45-a551-f5c96ae4bc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = lsa[:, :nb_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82a7d0-720d-4dff-abe4-c559de517094",
   "metadata": {},
   "source": [
    "## Évaluer la similarité entre deux documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93600375-ad4f-4d4b-8547-11cd28beb46d",
   "metadata": {},
   "source": [
    "Nous disposons à présent d’une structure de données qui décrit 7613 documents par 241 composantes issues de la vectorisation sémantique des contenus :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e965ba-d3b1-4955-9b60-9b2180d91acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e4ea4-4607-4a8a-b57b-5f2495dd1bbc",
   "metadata": {},
   "source": [
    "La question qui se pose à nous maintenant est de savoir, pour un document donné, lesquels lui sont le plus similaire. Pouvoir y répondre est la première marche d’une autre tâche assez courante en traitement automatique du langage, le *clustering*. Si nous ne traiterons pas du sujet ici, nous pouvons malgré tout dresser un tableau des similarités cosinus entre tous les documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561b345-7532-4e2e-ab78-7daf61439bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine = cosine_similarity(lsa, lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bf7c5-79c1-47a5-bcee-07a2e7ddb6eb",
   "metadata": {},
   "source": [
    "Cette nouvelle matrice indique, pour chaque vecteur (document), le cosinus de l’angle qu’il forme avec tous les autres dans un intervalle $[-1,1]$. Pour le premier document nous avons :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe1791-a674-4df2-af14-9089c776ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f1d64d-69dc-4488-bc5a-e54fd70b400b",
   "metadata": {},
   "source": [
    "Dans cet aperçu nous comprenons que le premier document est colinéaire à lui-même comme le cosinus de leur angle est de 1. Regardons en dehors de lui-même quel est le document dont il est le plus proche :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b00ebe3-31a5-4215-a65e-c2ce6f08ea07",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.argmax(cosine[0][1:])\n",
    "print(\n",
    "    df.text[0],\n",
    "    df.text[idx],\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04446575-60db-4fc4-87fc-375a243d6d88",
   "metadata": {},
   "source": [
    "Les deux semblent assez éloignés et, à raison, car leur cosinus est seulement de $0.0308$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27814a3c-cd38-491b-9e28-ae87dca013a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine[0][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573bef5b-d66e-4582-aef1-721cde61efb7",
   "metadata": {},
   "source": [
    "Comparons maintenant avec deux autres tweets dont la similarité cosinus est de 0.7038 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009b929-3d47-444d-8761-04b56db89bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = 144\n",
    "idx = np.argmax(cosine[tweet_id][1:])\n",
    "\n",
    "print(\n",
    "    f\"Tweet {tweet_id} : {df.text[tweet_id]}\",\n",
    "    f\"Tweet {idx} : {df.text[idx]}\",\n",
    "    f\"Similarité cosinus : {cosine[tweet_id][idx]:.4f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221bdf15-6a5e-41b6-b6ba-9ddaa0c50821",
   "metadata": {},
   "source": [
    "## Effectuer des prédictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e199713-8d62-487b-ae93-ea253164d527",
   "metadata": {},
   "source": [
    "Il est temps de programmer un algorithme prédictif afin de confronter notre analyse à la réalité. Commençons par découper le jeu de données en jeux d’entraînement et de tests :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c29e0a-2a83-4208-9c2e-d40a53fae6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lsa, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa3a34-d23d-4e11-8cc4-ca19723f52ca",
   "metadata": {},
   "source": [
    "Choisissons un algorithme de régression de logistique qui se prête bien à une tâche de classification :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82272c4-f889-45a1-bde4-f83b89d35b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=42)\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f0502c-05cd-41d9-b8d1-3d5f0a8337be",
   "metadata": {},
   "source": [
    "Effectuons les prédictions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fe4d2f-513d-4e53-a523-749c968ed156",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e284f9-780e-493e-afa6-ba354a7f237d",
   "metadata": {},
   "source": [
    "Et affichons le taux d’exactitude de notre programme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876690c7-77f7-4e95-a532-d2a3868e5079",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b519e-43e8-4cb8-8e5c-140d0d0df2bc",
   "metadata": {},
   "source": [
    "## Évaluer le modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9305fa-f2bb-4e77-958b-8a2bfe203912",
   "metadata": {},
   "source": [
    "Pour évaluer notre modèle, nous disposons d’outils plus performants que l’exactitude. Les métriques couramment utilisées sont la précision, le rappel et la moyenne harmonique entre les deux, le résultat F1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317b6f40-55a0-41fe-8735-85db0efcde04",
   "metadata": {},
   "source": [
    "### La matrice de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f127ef-7c59-46ee-83e8-a6b61c919e36",
   "metadata": {},
   "source": [
    "Avant de calculer les différentes mesures statistiques de la performance d’un classificateur, affichons une matrice de confusion :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809748af-5ce3-4740-8e74-ec019b27c995",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfm = confusion_matrix(y_test, y_pred)\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cfm, display_labels=model.classes_)\n",
    "_ = display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05befda8-cab2-4874-83fc-21d3b54b3bb0",
   "metadata": {},
   "source": [
    "Chaque ligne correspond à une classe réelle et chaque colonne à une classe prédite avec, sur la première ligne, la classe négative et, sur la seconde, la classe positive, tel que dans le tableau suivant :\n",
    "\n",
    "|prédites/réelles|Classe négative|Classe positive|\n",
    "|-|:-:|:-:|\n",
    "|Classe négative|TN (769)|FP (105)|\n",
    "|Classe positive|FN (237)|TP (412)|\n",
    "\n",
    "Cela signifie que, sur 874 faux tweets, notre programme en a repéré 769 et que sur 649 traitant de catastrophes réelles, il n’en a identifié que 412."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5597c2a1-1d53-4ede-93aa-2b8fd5f96b6a",
   "metadata": {},
   "source": [
    "### Les mesures de la performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f99c8fc-94e6-4a43-a6ff-92d696f12ddc",
   "metadata": {},
   "source": [
    "Pour un classificateur binaire, il est commun de ressortir les trois mesures statistiques :\n",
    "\n",
    "- la précision (exactitude des prédictions positives) ;\n",
    "- le rappel (taux de classes positives correctement étiquetées) ;\n",
    "- le score F1 (compromis précision/rappel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17ea72-9af9-4aa5-adef-7a25d6e5b7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Précision : {precision_score(y_test, y_pred):.2%}\",\n",
    "    f\"Rappel : {recall_score(y_test, y_pred):.2%}\",\n",
    "    f\"F1 score : {f1_score(y_test, y_pred):.2%}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4a9b1-785e-4686-907b-42d31ef0cb2c",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f491d5-2d07-4b9f-a249-e453d3e0ee75",
   "metadata": {},
   "source": [
    "Atteindre au plus vite l’objectif. C'est le motif qui nous a guidés au long de ce parcours, aussi n’avons-nous envisagé à aucun moment d’améliorer l’efficacité de notre programme. Nous aurions pu appliquer une phase de normalisation du texte en résolvant les contractions de l’anglais, en supprimant les émojis, les URLs et autres caractères indésirables ; nous aurions pu tout aussi bien vérifier le niveau de langage, la justesse de l’orthographe ou la présence de doublons ; nous aurions pu augmenter nos données avec des mesures classiques comme la longueur du texte en nombre de mots ou la longueur moyenne d’un mot ; nous aurions sans doute dû créer un sac de mots préalablement à la vectorisation en matrice TF-IDF ; et il aurait aussi été judicieux d’évaluer la pertinence de nos choix à chaque étape grâce à des mesures statistiques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
