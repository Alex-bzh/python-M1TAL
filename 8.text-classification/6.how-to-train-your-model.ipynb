{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51cb8e3f-0369-47ba-b219-9257137b9e5d",
   "metadata": {},
   "source": [
    "# Comment entraîner proprement un modèle d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f3a8a-aad9-409b-a6df-f1bd6caed41b",
   "metadata": {},
   "source": [
    "Jusqu’à présent, nous avons abordé les concepts essentiels de l’apprentissage supervisé très simplement, en les répartissant dans des étapes incontournables de tout projet de *machine learning*. De la constitution du jeu de données à l’entraînement du modèle en passant par la visualisation des interactions entre les variables explicatives et leur pré-traitement (recodage, mise à l’échelle, gestion des données manquantes…), il est en quelques manipulations possible d’obtenir des résultats satisfaisants avec les outils de *Scikit-Learn* dans la mesure où l’on est certain·es de disposer de données fiables et d’avoir fixé un objectif compréhensible.\n",
    "\n",
    "La réalité est plus nuancée. Si notre volonté n’est pas de dresser un panorama exhaustif des techniques de paramétrage d’un modèle d’apprentissage et de leurs subtilités, pour cela nous renvoyons à des ouvrages plus complets comme celui de Aurélien Géron, [*Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/), notre intention est d’infuser un certain nombre de réflexes propres à éviter les principaux écueils inhérents aux méthodes statistiques.\n",
    "\n",
    "Commençons par charger les librairies nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522a31-de37-42e3-a1ec-a22cf76e6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ad19c-f0a3-457f-9c7d-ea5051a99adc",
   "metadata": {},
   "source": [
    "## Du problème de l’ajustement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a539e32-9b95-4eeb-8d62-933964c96ed0",
   "metadata": {},
   "source": [
    "Nous avons souvent évoqué les difficultés rencontrées par les modèles d’apprentissage pour s’ajuster aux données sans vraiment expliquer concrètement les deux cas de figure qui peuvent se présenter :\n",
    "- Le **sous-ajustement** (*underfitting*), survenant lorsque le modèle ne parvient pas à percevoir la forme des données ;\n",
    "- le **sur-ajustement** (*overfitting*), souvent caractérisé par des erreurs de généralisation bien plus importantes que celles d’entraînement.\n",
    "\n",
    "L’objectif n’est donc pas d’obtenir le meilleur score sur le jeu d’entraînement ou, pire, sur le jeu de test, mais bien de trouver la zone idéale qui minimise l’écart entre les erreurs d’entraînement et de généralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7258a-0fb7-4fe7-8144-09942876946b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Facteur de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a6aca-bb42-4023-9038-70bf75a7a795",
   "metadata": {},
   "source": [
    "Avant d’entrer dans le vif du sujet, abordons un piège fondamental qui peut apparaître dès la définition du projet de *machine learning*. Imaginons que l’on souhaite modéliser un programme qui permette de prédire l’ampleur du bec d’un manchot et, comme variable explicative, nous retenons son poids.\n",
    "\n",
    "Chargeons les données sur le recensement de trois espèces de manchots de l’Antarctique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc19fa2-4087-4c34-998d-71b3819e3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/penguin-census.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f4c2f-b8d7-4699-96f9-f674cfa8544f",
   "metadata": {},
   "source": [
    "Un modèle simple de régression linéaire nous apprend qu’il existe une corrélation négative entre les deux variables, si bien que le bec d’un manchot s’affine à mesure que sa masse corporelle augmente. Les chiffres ne mentent pas et, si l’on considère en prime l’intervalle de confiance à 95 %, la marge d’erreur est somme toute raisonnable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0ab21-c854-489f-8572-b0a170ea1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.regplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86a6fe-6826-4310-b290-cc944d569875",
   "metadata": {},
   "source": [
    "La déduction nous semble malgré tout contre-intuitive. On aurait plutôt tendance à penser que les propriétés physiques de tout organisme biologique croissent proportionnellement à sa masse, non ?\n",
    "\n",
    "Essayons de comprendre l’erreur de méthodologie que nous avons commise. Sur le graphique que nous venons d’afficher se distinguent deux groupes de points. Peut-être existe-t-il une différence entre les individus mâles et les individus femelles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2439979-4f25-4cf6-8718-254c9748ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"sex\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc4ba-4f12-4674-b7d4-881279420dbf",
   "metadata": {},
   "source": [
    "Eh bien, non, cette hypothèse nous conforte dans notre erreur. Avant de supposer une différenciation de genre, rappelons-nous plutôt que la grande famille des manchots est subdivisée en plusieurs espèces avec des disparités physiques fortes et regardons le comportement de notre modèle linéaire à la lumière de ce nouveau facteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92162682-09d3-42c5-94c3-01417eb0d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"species\", hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cbd24-5f46-4c62-85d6-2555e916b3fc",
   "metadata": {},
   "source": [
    "D’une corrélation négative entre la masse et l’épaisseur du bec d’un manchot nous sommes passés à une corrélation positive et avons évité de graves erreurs de généralisation au moment de la production de notre modèle.\n",
    "\n",
    "Dans notre exemple, l’espèce d’appartenance d’un manchot est ce que l’on nomme un facteur de confusion, en ce sens qu’elle influe non seulement sur la variable cible, l’épaisseur du bec, mais aussi sur la variable explicative, la masse corporelle. En effet, si nous nous permettons une analyse grossière, un manchot papou ne peut pas peser moins de 4 kgs et son bec ne dépassera pas les 18 mm d’épaisseur pour les mieux lotis quand celui d’un manchot Adélie peut atteindre les 22 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5f513-26bd-44f4-b6e6-bde85dc49906",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Comparaison entre les erreurs d’entraînement et de généralisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3376f2-4696-45a0-81d1-21a44ba3b0ff",
   "metadata": {},
   "source": [
    "La compréhension des notions liées à l’ajustement d’un modèle passe par la comparaison des erreurs sur les jeux d’entraînement et de test. Prenons tout d’abord un ensemble de points à l’aspect sinusoïdal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da651b-9857-4ff0-8e50-56200e445bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deterministic purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# three hundred points\n",
    "X = np.linspace(0, 10, 300).reshape(-1, 1)\n",
    "\n",
    "# sinusoid function + noise\n",
    "y = np.sin(X) + np.random.rand(300, 1)\n",
    "\n",
    "coords = pd.DataFrame({\n",
    "    'x': X[:, 0],\n",
    "    'y': y[:, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d56b5c-c304-4401-aca4-cf82ea429b5b",
   "metadata": {},
   "source": [
    "Si nous affichons un nuage de points, une forme se dessine clairement, nous laissant une vague idée sur la forme de la ligne qui devrait minimiser la fonction de coût :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c6918-ab9c-4a52-abcb-e4ea8a8270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(data=coords, x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77046e6d-1650-4106-af74-bc286bd03192",
   "metadata": {},
   "source": [
    "Constituons maintenant les jeux d’entraînement et de test selon une partition 80/20 et essayons d’entraîner dessus un modèle de régression linéaire que nous savons d’ores et déjà voué à l’échec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb05b8-b65b-4e60-9b28-b2a3dca34884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(coords[\"x\"].values.reshape(-1,1), coords[\"y\"], test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708afae-8119-4f3a-84a9-b61540b3ac1e",
   "metadata": {},
   "source": [
    "Les prédictions sont désastreuses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16d32e-32ff-4900-a0de-bcba61fb6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# plot test points\n",
    "ax = sns.scatterplot(x=X_test[:, 0], y=y_test)\n",
    "ax.plot(X_test, y_pred, color=\"orange\")\n",
    "_ = ax.set_title(f\"R2 scores: train = {model.score(X_train, y_train):.3f} ; test = {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a79f8-a21f-46dc-9d12-9c9ad62f092f",
   "metadata": {},
   "source": [
    "D’un côté, en étant inférieur sur les données de test, le $R^2$ score est conforme à nos attentes ; d’un autre côté, il est révélateur d’un modèle sévèrement sous-ajusté.\n",
    "\n",
    "Confirmons ce résultat en calculant maintenant l’erreur absolue moyenne (*mean absolute error*) et rappelons que si un score doit être le plus élevé possible, une erreur doit quant à elle être la plus faible possible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b16a09-e346-4cf2-83dd-ca9649491e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\n",
    "    f\"MAE (jeu d’entrainement) : {mae_train:.3f}\",\n",
    "    f\"MAE (jeu de test) : {mae_test:.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fb24f-81e5-48b2-868a-5453aef7135a",
   "metadata": {},
   "source": [
    "L’erreur sur le jeu de test est encore plus importante que sur le jeu d’entraînement : aucun doute possible, le modèle est sous-ajusté.\n",
    "\n",
    "Reprenons nos efforts en entraînant désormais un modèle de régression polynomial à haut degré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4225-f7ee-4c9b-8cfa-5efbdb37b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=25),\n",
    "    LinearRegression(),\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "mae_test = mean_absolute_error(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702654f6-c1c1-4173-be85-e93c94b67fab",
   "metadata": {},
   "source": [
    "La MAE sur le jeu d’entraînement reste élevée tandis qu’elle a baissé sur le jeu de test au point de lui être inférieure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46dd1b-009d-4770-86d5-26f97a8f25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_test[:, 0], y=y_test, ax=ax)\n",
    "sns.lineplot(x=X_test[:, 0], y=y_test_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE: train = {mae_train:.3f} ; test = {mae_test:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8d84d-8c38-489c-8bd8-139e444385cf",
   "metadata": {},
   "source": [
    "On s’attendrait en fait à l’inverse d’un modèle justement entraîné, l’idée qu’il soit moins performant sur des données nouvelles étant tout à fait naturelle. En tâtonnant un peu, on finirait par trouver qu’un polynôme de degré 7 ou 8 constitue le meilleur choix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb17c2-578b-4956-ba8d-bd57970ea854",
   "metadata": {},
   "source": [
    "## Entraîner, tester, valider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63f0a1-ca6f-4c2b-aa0a-96a6112f336c",
   "metadata": {},
   "source": [
    "## Régulariser un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290a347-3c57-4203-b922-fada49ffc32c",
   "metadata": {},
   "source": [
    "## Sauvegarder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
