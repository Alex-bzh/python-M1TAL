{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51cb8e3f-0369-47ba-b219-9257137b9e5d",
   "metadata": {},
   "source": [
    "# Fondamentaux de l’entraînement de modèles pour l’apprentissage supervisé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f3a8a-aad9-409b-a6df-f1bd6caed41b",
   "metadata": {},
   "source": [
    "Jusqu’à présent, nous avons abordé les concepts essentiels de l’apprentissage supervisé très simplement, en les répartissant dans des étapes incontournables de tout projet de *machine learning*. De la constitution du jeu de données à l’entraînement du modèle en passant par la visualisation des interactions entre les variables explicatives et leur pré-traitement (recodage, mise à l’échelle, gestion des données manquantes…), il est en quelques manipulations possible d’obtenir des résultats satisfaisants avec les outils de *Scikit-Learn* dans la mesure où l’on est certain·es de disposer de données fiables et d’avoir fixé un objectif compréhensible.\n",
    "\n",
    "La réalité est plus nuancée. Si notre volonté n’est pas de dresser un panorama exhaustif des techniques de paramétrage d’un modèle d’apprentissage et de leurs subtilités, pour cela nous renvoyons à des ouvrages plus complets comme celui de Aurélien Géron, [*Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/), notre intention est d’infuser un certain nombre de réflexes propres à éviter les principaux écueils inhérents aux méthodes statistiques.\n",
    "\n",
    "Commençons par charger les librairies nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522a31-de37-42e3-a1ec-a22cf76e6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ad19c-f0a3-457f-9c7d-ea5051a99adc",
   "metadata": {},
   "source": [
    "## Du problème de l’ajustement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a539e32-9b95-4eeb-8d62-933964c96ed0",
   "metadata": {},
   "source": [
    "Nous avons souvent évoqué les difficultés rencontrées par les modèles d’apprentissage pour s’ajuster aux données sans vraiment expliquer concrètement les deux cas de figure qui peuvent se présenter :\n",
    "- Le **sous-ajustement** (*underfitting*), survenant lorsque le modèle ne parvient pas à percevoir la forme des données ;\n",
    "- le **sur-ajustement** (*overfitting*), souvent caractérisé par des erreurs de généralisation bien plus importantes que celles d’entraînement.\n",
    "\n",
    "L’objectif n’est donc pas d’obtenir le meilleur score sur le jeu d’entraînement ou, pire, sur le jeu de test, mais bien de trouver la zone idéale qui minimise l’écart entre les erreurs d’entraînement et de généralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7258a-0fb7-4fe7-8144-09942876946b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Facteur de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a6aca-bb42-4023-9038-70bf75a7a795",
   "metadata": {},
   "source": [
    "Avant d’entrer dans le vif du sujet, abordons un piège fondamental qui peut apparaître dès la définition du projet de *machine learning*. Imaginons que l’on souhaite modéliser un programme qui permette de prédire l’ampleur du bec d’un manchot et, comme variable explicative, nous retenons son poids.\n",
    "\n",
    "Chargeons les données sur le recensement de trois espèces de manchots de l’Antarctique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc19fa2-4087-4c34-998d-71b3819e3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/penguin-census.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f4c2f-b8d7-4699-96f9-f674cfa8544f",
   "metadata": {},
   "source": [
    "Un modèle simple de régression linéaire nous apprend qu’il existe une corrélation négative entre les deux variables, si bien que le bec d’un manchot s’affine à mesure que sa masse corporelle augmente. Les chiffres ne mentent pas et, si l’on considère en prime l’intervalle de confiance à 95 %, la marge d’erreur est somme toute raisonnable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0ab21-c854-489f-8572-b0a170ea1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.regplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86a6fe-6826-4310-b290-cc944d569875",
   "metadata": {},
   "source": [
    "La déduction nous semble malgré tout contre-intuitive. On aurait plutôt tendance à penser que les propriétés physiques de tout organisme biologique croissent proportionnellement à sa masse, non ?\n",
    "\n",
    "Essayons de comprendre l’erreur de méthodologie que nous avons commise. Sur le graphique que nous venons d’afficher se distinguent deux groupes de points. Peut-être existe-t-il une différence entre les individus mâles et les individus femelles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2439979-4f25-4cf6-8718-254c9748ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"sex\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc4ba-4f12-4674-b7d4-881279420dbf",
   "metadata": {},
   "source": [
    "Eh bien, non, cette hypothèse nous conforte dans notre erreur. Avant de supposer une différenciation de genre, rappelons-nous plutôt que la grande famille des manchots est subdivisée en plusieurs espèces avec des disparités physiques fortes et regardons le comportement de notre modèle linéaire à la lumière de ce nouveau facteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92162682-09d3-42c5-94c3-01417eb0d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"species\", hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cbd24-5f46-4c62-85d6-2555e916b3fc",
   "metadata": {},
   "source": [
    "D’une corrélation négative entre la masse et l’épaisseur du bec d’un manchot nous sommes passés à une corrélation positive et avons évité de graves erreurs de généralisation au moment de la production de notre modèle.\n",
    "\n",
    "Dans notre exemple, l’espèce d’appartenance d’un manchot est ce que l’on nomme un facteur de confusion, en ce sens qu’elle influe non seulement sur la variable cible, l’épaisseur du bec, mais aussi sur la variable explicative, la masse corporelle. En effet, si nous nous permettons une analyse grossière, un manchot papou ne peut pas peser moins de 4 kgs et son bec ne dépassera pas les 18 mm d’épaisseur pour les mieux lotis quand celui d’un manchot Adélie peut atteindre les 22 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5f513-26bd-44f4-b6e6-bde85dc49906",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Erreurs d’entraînement et de généralisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36aa32-64bc-426a-b36d-f16d1c2809b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comparer les chiffres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3376f2-4696-45a0-81d1-21a44ba3b0ff",
   "metadata": {},
   "source": [
    "La compréhension des notions liées à l’ajustement d’un modèle passe par la comparaison des erreurs sur les jeux d’entraînement et de test. Prenons tout d’abord un ensemble de points à l’aspect sinusoïdal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da651b-9857-4ff0-8e50-56200e445bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deterministic purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# three hundred points\n",
    "X = np.linspace(0, 10, 300).reshape(-1, 1)\n",
    "\n",
    "# sinusoid function + noise\n",
    "y = np.sin(X) + np.random.rand(300, 1)\n",
    "\n",
    "# into a DF\n",
    "coords = pd.DataFrame({\n",
    "    'x': X[:, 0],\n",
    "    'y': y[:, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d56b5c-c304-4401-aca4-cf82ea429b5b",
   "metadata": {},
   "source": [
    "Si nous affichons un nuage de points, une forme se dessine clairement, nous laissant une vague idée sur la forme de la ligne qui devrait minimiser la fonction de coût :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c6918-ab9c-4a52-abcb-e4ea8a8270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(data=coords, x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77046e6d-1650-4106-af74-bc286bd03192",
   "metadata": {},
   "source": [
    "Constituons maintenant les jeux d’entraînement et de test selon une partition 80/20 et essayons d’entraîner dessus un modèle de régression linéaire que nous savons d’ores et déjà voué à l’échec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb05b8-b65b-4e60-9b28-b2a3dca34884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(coords[\"x\"].values.reshape(-1,1), coords[\"y\"], test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708afae-8119-4f3a-84a9-b61540b3ac1e",
   "metadata": {},
   "source": [
    "Les prédictions sont désastreuses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16d32e-32ff-4900-a0de-bcba61fb6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# plot test points\n",
    "ax = sns.scatterplot(x=X_test[:, 0], y=y_test)\n",
    "ax.plot(X_test, y_pred, color=\"orange\")\n",
    "_ = ax.set_title(f\"R2 scores: train = {model.score(X_train, y_train):.3f} ; test = {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a79f8-a21f-46dc-9d12-9c9ad62f092f",
   "metadata": {},
   "source": [
    "D’un côté, en étant inférieur sur les données de test, le $R^2$ score est conforme à nos attentes ; d’un autre côté, il est révélateur d’un modèle sévèrement sous-ajusté.\n",
    "\n",
    "Confirmons ce résultat en calculant maintenant l’erreur absolue moyenne (*mean absolute error*) et rappelons que si un score doit être le plus élevé possible, une erreur doit quant à elle être la plus faible possible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b16a09-e346-4cf2-83dd-ca9649491e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\n",
    "    f\"MAE (jeu d’entrainement) : {mae_train:.3f}\",\n",
    "    f\"MAE (jeu de test) : {mae_test:.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fb24f-81e5-48b2-868a-5453aef7135a",
   "metadata": {},
   "source": [
    "L’erreur sur le jeu de test est encore plus importante que sur le jeu d’entraînement : aucun doute possible, le modèle est sous-ajusté.\n",
    "\n",
    "Reprenons nos efforts en entraînant désormais un modèle de régression polynomiale à haut degré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4225-f7ee-4c9b-8cfa-5efbdb37b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=25),\n",
    "    LinearRegression(),\n",
    ")\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "mae_test = mean_absolute_error(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702654f6-c1c1-4173-be85-e93c94b67fab",
   "metadata": {},
   "source": [
    "La MAE sur le jeu d’entraînement reste élevée tandis qu’elle a baissé sur le jeu de test au point de lui être inférieure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46dd1b-009d-4770-86d5-26f97a8f25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_test[:, 0], y=y_test, ax=ax)\n",
    "sns.lineplot(x=X_test[:, 0], y=y_test_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE: train = {mae_train:.3f} ; test = {mae_test:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8d84d-8c38-489c-8bd8-139e444385cf",
   "metadata": {},
   "source": [
    "On s’attendrait en fait à l’inverse d’un modèle justement entraîné, l’idée qu’il soit moins performant sur des données nouvelles étant tout à fait naturelle. En tâtonnant un peu, on finirait par trouver qu’un polynôme de degré 7 ou 8 constitue le meilleur choix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1116176-88ea-4f62-8cb2-ffa463168da2",
   "metadata": {},
   "source": [
    "#### Améliorer l’estimation par la validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34382d97-7b3e-47d4-8196-3e8fc806ef66",
   "metadata": {},
   "source": [
    "En réalisant aveuglément les évaluations de nos modèles au moment des phases d’entraînement et de test, nous avons mis au jour quelques incertitudes quant à leur crédibilité. Observons l’ampleur de l’enjeu avec un modèle basé sur un arbre de décision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df468c6c-aca5-40ac-831e-43ae992bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "\n",
    "# plot\n",
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_train[:, 0], y=y_train, ax=ax)\n",
    "sns.lineplot(x=X_train[:, 0], y=y_train_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE (train set) = {mae_train:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8bcd13-3110-4ebc-95ac-963f843f1275",
   "metadata": {},
   "source": [
    "Une MAE à 0.0 ! Un score parfait qui nous satisferait si l’on n’était conscient·es de la nette tendance des arbres de décision à sur-ajuster. Le graphique est explicite : sans contrainte, le tracé suit tous les points du jeu d’entraînement.\n",
    "\n",
    "Dans la pratique, avant de passer à l’étape de généralisation, il convient de s’assurer que le modèle entraîné est fiable. Pour cela, rien de plus évident, il nous suffirait de découper le jeu d’entraînement en deux sous-ensembles avec la fonction `train_test_split()` : un pour l’entraînement effectif et l’autre pour la validation.\n",
    "\n",
    "*Scikit-Learn* propose un outil plus performant pour réaliser ce que l’on appelle une validation croisée en $K$ passes. C’est les fonctions `cross_validate()` ou `cross_val_score()` lorsque l’on n’est intéressé·es que par les métriques. Le procédé consiste à découper le *dataset* en $K$ parties puis à effectuer $K$ évaluations en prenant à chaque passe $K - 1$ sous-ensembles pour l’entraînement et le restant, qui ne sera jamais le même, pour la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c8eae-0e89-4f3b-b956-0fb9229b7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10 ; score = -MAE\n",
    "scores = cross_val_score(model, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "# -MAE into MAE\n",
    "scores = -scores\n",
    "\n",
    "print(\n",
    "    f\"MAE moyenne : {scores.mean():.3f}\",\n",
    "    f\"Écart-type : {scores.std():.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8600721-7dd2-4495-bcb4-67dcc25d7b82",
   "metadata": {},
   "source": [
    "Après validation croisée, notre modèle nous semble largement moins convaincant ! Il ne nous reste plus qu’à tout reprendre de zéro et à travailler sur les différentes solutions pour l’améliorer : changer d’algorithme, augmenter le nombre d’observations d’entraînement ou encore lui imposer des contraintes afin de le régulariser.\n",
    "\n",
    "**Remarque :** le paramètre `scoring` de la fonction `cross_val_score()` attend une fonction d’utilité, où la valeur la plus haute est considérée comme la meilleure, et non une fonction de coût, où la valeur la plus basse est réputée la plus forte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a9905-1dd0-4f58-8eff-497ebb0e137c",
   "metadata": {},
   "source": [
    "#### Visualiser les courbes d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87b9f5-a378-47d3-adda-96139041df20",
   "metadata": {},
   "source": [
    "Une bonne manière de se représenter les phénomènes de sous-ajustement et de sur-ajustement consiste à afficher les courbes de validation du modèle en fonction d’un paramètre avec la fonction `validation_curve()`. Dans notre exemple, nous avons utilisé un arbre de décision que l’on sait avoir tendance à sur-ajuster et nous sélectionnons deux paramètres réputés le régulariser : `max_depth` pour définir la profondeur maximale de l’arbre et `min_samples_leaf` pour fixer le nombre minimum d’observations à considérer dans un nœud de l’arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466eafb-b402-45a3-a218-8dbb59c24ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# several values for each param\n",
    "max_depth = [1, 4, 5, 7, 10, 25]\n",
    "min_samples_leaf = [1, 3, 5, 7, 10, 15]\n",
    "\n",
    "# param = max_depth ; score = -MAE\n",
    "max_depth_train_scores, max_depth_test_scores = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name=\"max_depth\", param_range=max_depth,\n",
    "    cv=10, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "# param = min_samples_leaf ; score = -MAE\n",
    "min_samples_leaf_train_scores, min_samples_leaf_test_scores = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name=\"min_samples_leaf\", param_range=min_samples_leaf,\n",
    "    cv=10, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "# -MAE into MAE\n",
    "max_depth_train_errors, max_depth_test_errors = -max_depth_train_scores, -max_depth_test_scores\n",
    "min_samples_leaf_train_errors, min_samples_leaf_test_errors = -min_samples_leaf_train_scores, -min_samples_leaf_test_scores\n",
    "\n",
    "# plot\n",
    "figure, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n",
    "\n",
    "sns.lineplot(x=max_depth, y=max_depth_train_errors.mean(axis=1), ax=ax1)\n",
    "sns.lineplot(x=max_depth, y=max_depth_test_errors.mean(axis=1), ax=ax1)\n",
    "sns.lineplot(x=min_samples_leaf, y=min_samples_leaf_train_errors.mean(axis=1), ax=ax2)\n",
    "sns.lineplot(x=min_samples_leaf, y=min_samples_leaf_test_errors.mean(axis=1), ax=ax2)\n",
    "\n",
    "ax1.set(\n",
    "    title=\"Paramètre : max_depth\",\n",
    "    xlabel=\"Profondeur maximale de l’arbre\",\n",
    "    ylabel=\"Erreur absolue moyenne\"\n",
    ")\n",
    "ax2.set(\n",
    "    title=\"Paramètre : min_samples_leaf\",\n",
    "    xlabel=\"Nombre minimum d’observations dans un nœud\",\n",
    "    ylabel=\"Erreur absolue moyenne\"\n",
    ")\n",
    "ax1.legend(title=\"Jeux de données\", labels=[\"entraînement\", \"validation\"])\n",
    "ax2.legend(title=\"Jeux de données\", labels=[\"entraînement\", \"validation\"])\n",
    "\n",
    "figure.suptitle(\"Courbes de validation de l’arbre de décision\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ea4b0-6c2d-4460-81bd-947e0b52aef1",
   "metadata": {},
   "source": [
    "L’analyse des graphiques nous révèle les valeurs idéales pour les paramètres de régularisation :\n",
    "- `max_depth` : 5\n",
    "- `min_samples_leaf`: 3\n",
    "\n",
    "Pour chacun d’eux, nous distinguons trois zones :\n",
    "1. Tant que la valeur du paramètre est inférieure à celle idéale, le modèle sous-ajuste. Il n’a pas assez de degré de liberté pour comprendre toutes les variations de la variable cible. La MAE est forte pour les deux tracés.\n",
    "2. Lorsque le tracé de la MAE pour le jeu de validation cesse de décroître, le modèle a atteint la zone où il généralise le mieux.\n",
    "3. Sitôt que la valeur idéale est dépassée, le modèle s’ajuste de plus en plus étroitement aux données d’entraînement et généralise de moins en moins bien.\n",
    "\n",
    "À ces observations, il faut en rajouter une sur l’écart entre les deux tracés. Dans le cas du paramètre `min_samples_leaf`, on serait tenté·es de retenir la valeur 5 comme la meilleure puisque la MAE sur le jeu de validation reste stable alors qu’elle baisse sur le jeu d’entraînement. En fait, cet écart montre que le modèle est en train de sur-ajuster, aussi est-il préférable d’opter pour la valeur qui minimise l’écart.\n",
    "\n",
    "**Remarque :** les paramètres ont été testés individuellement, sans essayer les différentes combinaisons entre eux. Nous verrons plus loin une méthode pour effectuer une recherche des meilleurs réglages des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb17c2-578b-4956-ba8d-bd57970ea854",
   "metadata": {},
   "source": [
    "## Entraîner, tester, valider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d80b04e-ba47-462a-b89f-b690c55ebb2f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sélectionner les variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ebd24-c115-4d72-9186-77e145bd6f5e",
   "metadata": {},
   "source": [
    "En fonction de l’objectif défini pour le programme d’apprentissage, il sera nécessaire de laisser de côté certaines variables du jeu de données. Deux perspectives peuvent nous aider à faire le tri :\n",
    "- Une expertise personnelle ou glanée auprès de spécialistes de la thématique ;\n",
    "- l’étude de la corrélation entre les variables explicatives et la variable cible.\n",
    "\n",
    "Laissons de côté la première pour expliquer la notion de corrélation entre variables. Si elles sont à l’origine réputées indépendantes, la recherche de corrélation va mettre en évidence une relation dont la prépondérance sera calculée par un coefficient. Rappelons qu’une corrélation n’est surtout pas la preuve de l’existence d’un lien de cause à effet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0494f-f51b-4187-a1a9-1277147d074a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Corrélation entre variables quantitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f83d6d-565e-4126-8a82-22ca3ede5672",
   "metadata": {},
   "source": [
    "Pour illustrer notre propos, chargeons plutôt en mémoire un jeu de données sur la satisfaction à l’égard de la vie des femmes des pays de l’OCDE et retenons uniquement quelques indicateurs pour des raisons de lisibilité :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a9a6b2-38cf-4b6c-9e70-bbd6e1c76b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset without na\n",
    "df = pd.read_csv(\"./data/better-life-index-women-2021.csv\", index_col=[0])\n",
    "es_edua_mean = int(df[\"ES_EDUA\"].mean())\n",
    "df[\"ES_EDUA\"].fillna(es_edua_mean, inplace=True)\n",
    "\n",
    "target = \"SW_LIFS\"\n",
    "features = [\"HS_LEB\", \"ES_EDUA\", \"SC_SNTWS\", \"PS_REPH\"]\n",
    "\n",
    "data = df[features + [target]]\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90c83b-d291-4a9f-8ece-41fda7e2aa48",
   "metadata": {},
   "source": [
    "Pour des variables quantitatives, nous pouvons invoquer la méthode `.corr()` qui dresse une matrice de corrélation avec, pour mesure par défaut, le $R$ de Pearson, où 0 indique une absence de corrélation et -1 et 1 une corrélation forte, qu’elle soit négative ou positive :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f96b53-4d75-4663-ad98-720e6c46d933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# method=\"pearson\"\n",
    "correlation_matrix = data.corr()\n",
    "# heatmap\n",
    "_ = sns.heatmap(correlation_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9a252a-fb13-4cc0-ad73-f7651f0d5e5d",
   "metadata": {},
   "source": [
    "Dans notre exemple, nous observons une corrélation positive assez forte entre la satisfaction à l’égard de la vie d’une part et, d’autre part, la qualité du réseau social ou l’espérance de vie. À l’inverse, le taux d’homicide semble influer négativement dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fae55ae-9bc0-4188-bf6c-6c81c849e98e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Corrélation entre variables qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c585f9b1-7421-4412-a8ba-307340333f6a",
   "metadata": {},
   "source": [
    "Pour des variables qualitatives, il n’existe malheureusement pas d’outil clé en main, mais nous pouvons nous reposer sur des tests statistiques éprouvés. Prenons une autre enquête, sur la satisfaction de patients relativement à leur séjour à l’hôpital :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4abb557-4699-48cb-ad9c-b2ee2da07da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data without na\n",
    "df = pd.read_csv(\"./data/satisfaction-hopital.csv\", sep=\";\")\n",
    "df.fillna(method=\"pad\", inplace=True)\n",
    "\n",
    "target = \"recommander\"\n",
    "features = [\"score.information\", \"score.relation\", \"amelioration.moral\", \"amelioration.sante\", \"sexe\", \"age\", \"profession\", \"service\"]\n",
    "\n",
    "data = df[features + [target]]\n",
    "X = data[features]\n",
    "y = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf16d8c-888d-48f3-913a-7853f10d9954",
   "metadata": {},
   "source": [
    "En dépit de leur allure numérique, la majorité des variables sont qualitatives. Retenons *service* et *recommander* en construisant une table de contingence à l’aide de la méthode `.crosstable()` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e18c2c-5867-4636-83d3-9d55f70b9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "contingency_table = pd.crosstab(data.service, data.recommander)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc93d23-57e1-430a-add6-28da708b7044",
   "metadata": {},
   "source": [
    "Émettons maintenant l’hypothèse nulle $H_0$ d’indépendance entre les deux variables, hypothèse que nous sommes prêt·es à rejeter au seuil de 5 %, et effectuons comme mesure le test du $\\chi^2$ (*Chi-squared test*) en nous reposant sur la fonction `chi2_contingency()` du module `stats` de la bibliothèque *SciPy* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e3c35-86ce-4252-af59-eb723c3f71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, exp = chi2_contingency(contingency_table)\n",
    "print(f\"Valeur-p : {p:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28bac5-7b66-4d09-bb68-d68936ba4c41",
   "metadata": {},
   "source": [
    "La valeur-p (*p-value*) est bien inférieure au seuil de 5 %, ce qui nous autorise à rejeter notre hypothèse nulle et à déclarer que la corrélation entre les variables *service* et *recommander* est statistiquement significative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b156bdbd-6c78-4826-9ff2-0104d9473604",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### L’échantillonnage stratifié"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b225bf31-11a2-4fdd-ae54-a6651dac901c",
   "metadata": {},
   "source": [
    "Dans le précédent chapitre, nous avons évoqué l’importance d’évaluer la performance du jeu d’entraînement avant de passer à l’étape de généralisation, sans pour autant préciser la manière de le construire proprement. Nous nous sommes même contentés d’une méthode purement aléatoire en faisant appel à la fonction `train_test_split()`. Si elle est satisfaisante en présence d’un volume considérable d’observations, le risque d’introduire un biais d’échantillonnage n’est pas négligeable lorsque les données manquent.\n",
    "\n",
    "Imaginons que, renseignements pris auprès de spécialistes du domaine, nous apprenons que la profession des patient·es est un facteur déterminant du score de satisfaction qu’ils et elles attribueront à leur séjour à l’hôpital. Regardons maintenant la distribution des individus par catégorie professionnelle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedde49-3f84-4d22-8802-827360d9cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.countplot(data=X, x=\"profession\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf30c38-876b-40d5-b247-46b97d3d9611",
   "metadata": {},
   "source": [
    "Au vu des disparités, nous souhaitons regrouper les professions dans des catégories plus larges qui n’ont de sens que du point de vue mathématique. Pour cette raison, nous n’expliquerons pas les indices attribués aux catégories professionnelles dans l’enquête et reportons ci-dessous uniquement les regroupement proposés :\n",
    "- 1, 2 et 8 ensemble ;\n",
    "- 3 ;\n",
    "- 4 avec 7 ;\n",
    "- 5 avec 6.\n",
    "\n",
    "Recodons à présent la catégorie dans une variable *prof_cat* et regardons la nouvelle répartition :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca91681-3afc-4c35-8fe1-6d42a8e4bc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X[\"profession\"] == 3, \"prof_cat\"] = \"3\"\n",
    "X.loc[(X[\"profession\"] == 1) | (X[\"profession\"] == 2) | (X.profession == 8), \"prof_cat\"] = \"1, 2 et 8\"\n",
    "X.loc[(X[\"profession\"] == 4) | (X[\"profession\"] == 7), \"prof_cat\"] = \"4 et 7\"\n",
    "X.loc[(X[\"profession\"] == 5) | (X[\"profession\"] == 6), \"prof_cat\"] = \"5 et 6\"\n",
    "\n",
    "_ = sns.countplot(data=X, x=\"prof_cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dde590-ae18-4104-8e0d-e2749ec3f27a",
   "metadata": {},
   "source": [
    "Les catégories sont plus équilibrées. Il ne nous reste plus qu’à constituer les différents jeux dont nous avons besoin pour analyser les écarts engendrés par la répartition aléatoire des observations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1e8574-a76b-45fc-9fc8-af5f6eb7a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train & test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# prop data set - prop train set\n",
    "X[\"prof_cat\"].value_counts() / len(X) - X_train[\"prof_cat\"].value_counts() / len(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f822e2e2-a5a6-4126-b384-7465004d1471",
   "metadata": {},
   "source": [
    "Les différences ne sont guère notables dans ce cas de figure, mais comme nous voulons que notre jeu d’entraînement reflète la même répartition de patient·es en fonction de leur profession que dans le jeu complet, nous optons pour un échantillonnage stratifié. Il se trouve que la fonction `train_test_split()` accepte un argument `stratify` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae65981d-552a-4f5e-8c4e-ceb1b0fa88a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, stratify=X[\"prof_cat\"], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21180be9-d8f7-4594-a21a-24d5cb2bd03d",
   "metadata": {},
   "source": [
    "Grâce à cette astuce, les écarts étant désormais infimes, nous sommes assurés de la représentativité de notre jeu d’entraînement sur le critère de la catégorie professionnelle des individus statistiques :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea78a31-a75b-47bd-ae41-f43e7edee56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X[\"prof_cat\"].value_counts() / len(X) - X_train_strat[\"prof_cat\"].value_counts() / len(X_train_strat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e605bc19-1362-4111-bc03-8690b91560c1",
   "metadata": {},
   "source": [
    "Et pour rendre plus propres nos jeux de données, nous pouvons supprimer la variable *prof_cat* créée artificiellement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc8c03-c45e-4d62-b8f8-d6b572513bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in [X, X_train, X_train_strat, X_test, X_test_strat]:\n",
    "    dataset.drop(columns=\"prof_cat\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63f0a1-ca6f-4c2b-aa0a-96a6112f336c",
   "metadata": {},
   "source": [
    "## Régulariser un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290a347-3c57-4203-b922-fada49ffc32c",
   "metadata": {},
   "source": [
    "## Sauvegarder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
