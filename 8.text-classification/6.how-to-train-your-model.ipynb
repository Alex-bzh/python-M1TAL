{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51cb8e3f-0369-47ba-b219-9257137b9e5d",
   "metadata": {},
   "source": [
    "# Comment entraîner proprement un modèle d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f3a8a-aad9-409b-a6df-f1bd6caed41b",
   "metadata": {},
   "source": [
    "Jusqu’à présent, nous avons abordé les concepts essentiels de l’apprentissage supervisé très simplement, en les répartissant dans des étapes incontournables de tout projet de *machine learning*. De la constitution du jeu de données à l’entraînement du modèle en passant par la visualisation des interactions entre les variables explicatives et leur pré-traitement (recodage, mise à l’échelle, gestion des données manquantes…), il est en quelques manipulations possible d’obtenir des résultats satisfaisants avec les outils de *Scikit-Learn* dans la mesure où l’on est certain·es de disposer de données fiables et d’avoir fixé un objectif compréhensible.\n",
    "\n",
    "La réalité est plus nuancée. Si notre volonté n’est pas de dresser un panorama exhaustif des techniques de paramétrage d’un modèle d’apprentissage et de leurs subtilités, pour cela nous renvoyons à des ouvrages plus complets comme celui de Aurélien Géron, [*Hands-on Machine Learning with Scikit-Learn, Keras and TensorFlow*](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/), notre intention est d’infuser un certain nombre de réflexes propres à éviter les principaux écueils inhérents aux méthodes statistiques.\n",
    "\n",
    "Commençons par charger les librairies nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3522a31-de37-42e3-a1ec-a22cf76e6037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ad19c-f0a3-457f-9c7d-ea5051a99adc",
   "metadata": {},
   "source": [
    "## Du problème de l’ajustement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a539e32-9b95-4eeb-8d62-933964c96ed0",
   "metadata": {},
   "source": [
    "Nous avons souvent évoqué les difficultés rencontrées par les modèles d’apprentissage pour s’ajuster aux données sans vraiment expliquer concrètement les deux cas de figure qui peuvent se présenter :\n",
    "- Le **sous-ajustement** (*underfitting*), survenant lorsque le modèle ne parvient pas à percevoir la forme des données ;\n",
    "- le **sur-ajustement** (*overfitting*), souvent caractérisé par des erreurs de généralisation bien plus importantes que celles d’entraînement.\n",
    "\n",
    "L’objectif n’est donc pas d’obtenir le meilleur score sur le jeu d’entraînement ou, pire, sur le jeu de test, mais bien de trouver la zone idéale qui minimise l’écart entre les erreurs d’entraînement et de généralisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e7258a-0fb7-4fe7-8144-09942876946b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Facteur de confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1a6aca-bb42-4023-9038-70bf75a7a795",
   "metadata": {},
   "source": [
    "Avant d’entrer dans le vif du sujet, abordons un piège fondamental qui peut apparaître dès la définition du projet de *machine learning*. Imaginons que l’on souhaite modéliser un programme qui permette de prédire l’ampleur du bec d’un manchot et, comme variable explicative, nous retenons son poids.\n",
    "\n",
    "Chargeons les données sur le recensement de trois espèces de manchots de l’Antarctique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc19fa2-4087-4c34-998d-71b3819e3588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/penguin-census.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f4c2f-b8d7-4699-96f9-f674cfa8544f",
   "metadata": {},
   "source": [
    "Un modèle simple de régression linéaire nous apprend qu’il existe une corrélation négative entre les deux variables, si bien que le bec d’un manchot s’affine à mesure que sa masse corporelle augmente. Les chiffres ne mentent pas et, si l’on considère en prime l’intervalle de confiance à 95 %, la marge d’erreur est somme toute raisonnable :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f0ab21-c854-489f-8572-b0a170ea1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.regplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86a6fe-6826-4310-b290-cc944d569875",
   "metadata": {},
   "source": [
    "La déduction nous semble malgré tout contre-intuitive. On aurait plutôt tendance à penser que les propriétés physiques de tout organisme biologique croissent proportionnellement à sa masse, non ?\n",
    "\n",
    "Essayons de comprendre l’erreur de méthodologie que nous avons commise. Sur le graphique que nous venons d’afficher se distinguent deux groupes de points. Peut-être existe-t-il une différence entre les individus mâles et les individus femelles ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2439979-4f25-4cf6-8718-254c9748ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"sex\", hue=\"sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205cc4ba-4f12-4674-b7d4-881279420dbf",
   "metadata": {},
   "source": [
    "Eh bien, non, cette hypothèse nous conforte dans notre erreur. Avant de supposer une différenciation de genre, rappelons-nous plutôt que la grande famille des manchots est subdivisée en plusieurs espèces avec des disparités physiques fortes et regardons le comportement de notre modèle linéaire à la lumière de ce nouveau facteur :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92162682-09d3-42c5-94c3-01417eb0d12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.lmplot(data=df, x=\"body_mass_g\", y=\"bill_depth_mm\", col=\"species\", hue=\"species\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cbd24-5f46-4c62-85d6-2555e916b3fc",
   "metadata": {},
   "source": [
    "D’une corrélation négative entre la masse et l’épaisseur du bec d’un manchot nous sommes passés à une corrélation positive et avons évité de graves erreurs de généralisation au moment de la production de notre modèle.\n",
    "\n",
    "Dans notre exemple, l’espèce d’appartenance d’un manchot est ce que l’on nomme un facteur de confusion, en ce sens qu’elle influe non seulement sur la variable cible, l’épaisseur du bec, mais aussi sur la variable explicative, la masse corporelle. En effet, si nous nous permettons une analyse grossière, un manchot papou ne peut pas peser moins de 4 kgs et son bec ne dépassera pas les 18 mm d’épaisseur pour les mieux lotis quand celui d’un manchot Adélie peut atteindre les 22 mm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee5f513-26bd-44f4-b6e6-bde85dc49906",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Erreurs d’entraînement et de généralisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36aa32-64bc-426a-b36d-f16d1c2809b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Comparer les chiffres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3376f2-4696-45a0-81d1-21a44ba3b0ff",
   "metadata": {},
   "source": [
    "La compréhension des notions liées à l’ajustement d’un modèle passe par la comparaison des erreurs sur les jeux d’entraînement et de test. Prenons tout d’abord un ensemble de points à l’aspect sinusoïdal :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da651b-9857-4ff0-8e50-56200e445bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for deterministic purposes\n",
    "np.random.seed(0)\n",
    "\n",
    "# three hundred points\n",
    "X = np.linspace(0, 10, 300).reshape(-1, 1)\n",
    "\n",
    "# sinusoid function + noise\n",
    "y = np.sin(X) + np.random.rand(300, 1)\n",
    "\n",
    "# into a DF\n",
    "coords = pd.DataFrame({\n",
    "    'x': X[:, 0],\n",
    "    'y': y[:, 0]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d56b5c-c304-4401-aca4-cf82ea429b5b",
   "metadata": {},
   "source": [
    "Si nous affichons un nuage de points, une forme se dessine clairement, nous laissant une vague idée sur la forme de la ligne qui devrait minimiser la fonction de coût :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c6918-ab9c-4a52-abcb-e4ea8a8270c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = sns.scatterplot(data=coords, x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77046e6d-1650-4106-af74-bc286bd03192",
   "metadata": {},
   "source": [
    "Constituons maintenant les jeux d’entraînement et de test selon une partition 80/20 et essayons d’entraîner dessus un modèle de régression linéaire que nous savons d’ores et déjà voué à l’échec :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb05b8-b65b-4e60-9b28-b2a3dca34884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(coords[\"x\"].values.reshape(-1,1), coords[\"y\"], test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6708afae-8119-4f3a-84a9-b61540b3ac1e",
   "metadata": {},
   "source": [
    "Les prédictions sont désastreuses :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16d32e-32ff-4900-a0de-bcba61fb6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# plot test points\n",
    "ax = sns.scatterplot(x=X_test[:, 0], y=y_test)\n",
    "ax.plot(X_test, y_pred, color=\"orange\")\n",
    "_ = ax.set_title(f\"R2 scores: train = {model.score(X_train, y_train):.3f} ; test = {model.score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117a79f8-a21f-46dc-9d12-9c9ad62f092f",
   "metadata": {},
   "source": [
    "D’un côté, en étant inférieur sur les données de test, le $R^2$ score est conforme à nos attentes ; d’un autre côté, il est révélateur d’un modèle sévèrement sous-ajusté.\n",
    "\n",
    "Confirmons ce résultat en calculant maintenant l’erreur absolue moyenne (*mean absolute error*) et rappelons que si un score doit être le plus élevé possible, une erreur doit quant à elle être la plus faible possible :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b16a09-e346-4cf2-83dd-ca9649491e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, model.predict(X_train))\n",
    "mae_test = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\n",
    "    f\"MAE (jeu d’entrainement) : {mae_train:.3f}\",\n",
    "    f\"MAE (jeu de test) : {mae_test:.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835fb24f-81e5-48b2-868a-5453aef7135a",
   "metadata": {},
   "source": [
    "L’erreur sur le jeu de test est encore plus importante que sur le jeu d’entraînement : aucun doute possible, le modèle est sous-ajusté.\n",
    "\n",
    "Reprenons nos efforts en entraînant désormais un modèle de régression polynomiale à haut degré :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751c4225-f7ee-4c9b-8cfa-5efbdb37b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline\n",
    "model = make_pipeline(\n",
    "    PolynomialFeatures(degree=25),\n",
    "    LinearRegression(),\n",
    ")\n",
    "# fit\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "mae_test = mean_absolute_error(y_test, y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702654f6-c1c1-4173-be85-e93c94b67fab",
   "metadata": {},
   "source": [
    "La MAE sur le jeu d’entraînement reste élevée tandis qu’elle a baissé sur le jeu de test au point de lui être inférieure :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46dd1b-009d-4770-86d5-26f97a8f25f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_test[:, 0], y=y_test, ax=ax)\n",
    "sns.lineplot(x=X_test[:, 0], y=y_test_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE: train = {mae_train:.3f} ; test = {mae_test:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d8d84d-8c38-489c-8bd8-139e444385cf",
   "metadata": {},
   "source": [
    "On s’attendrait en fait à l’inverse d’un modèle justement entraîné, l’idée qu’il soit moins performant sur des données nouvelles étant tout à fait naturelle. En tâtonnant un peu, on finirait par trouver qu’un polynôme de degré 7 ou 8 constitue le meilleur choix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1116176-88ea-4f62-8cb2-ffa463168da2",
   "metadata": {},
   "source": [
    "#### Améliorer l’estimation par la validation croisée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34382d97-7b3e-47d4-8196-3e8fc806ef66",
   "metadata": {},
   "source": [
    "En réalisant aveuglément les évaluations de nos modèles au moment des phases d’entraînement et de test, nous avons mis au jour quelques incertitudes quant à leur crédibilité. Observons l’ampleur de l’enjeu avec un modèle basé sur un arbre de décision :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df468c6c-aca5-40ac-831e-43ae992bef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DecisionTreeRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_train_predict = model.predict(X_train)\n",
    "\n",
    "# MAE\n",
    "mae_train = mean_absolute_error(y_train, y_train_predict)\n",
    "\n",
    "# plot\n",
    "figure, ax = plt.subplots()\n",
    "\n",
    "sns.scatterplot(x=X_train[:, 0], y=y_train, ax=ax)\n",
    "sns.lineplot(x=X_train[:, 0], y=y_train_predict, color=\"orange\", ax=ax)\n",
    "\n",
    "ax.set_title(f\"MAE (train set) = {mae_train:.3f}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8bcd13-3110-4ebc-95ac-963f843f1275",
   "metadata": {},
   "source": [
    "Une MAE à 0.0 ! Un score parfait qui nous satisferait si l’on n’était conscient·es de la nette tendance des arbres de décision à sur-ajuster. Le graphique est explicite : sans contrainte, le tracé suit tous les points du jeu d’entraînement.\n",
    "\n",
    "Dans la pratique, avant de passer à l’étape de généralisation, il convient de s’assurer que le modèle entraîné est fiable. Pour cela, rien de plus évident, il nous suffirait de découper le jeu d’entraînement en deux sous-ensembles avec la fonction `train_test_split()` : un pour l’entraînement effectif et l’autre pour la validation.\n",
    "\n",
    "*Scikit-Learn* propose un outil plus performant pour réaliser ce que l’on appelle une validation croisée en $K$ passes. C’est les fonctions `cross_validate()` ou `cross_val_score()` lorsque l’on n’est intéressé·es que par les métriques. Le procédé consiste à découper le *dataset* en $K$ parties puis à effectuer $K$ évaluations en prenant à chaque passe $K - 1$ sous-ensembles pour l’entraînement et le restant, qui ne sera jamais le même, pour la validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24c8eae-0e89-4f3b-b956-0fb9229b7d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K = 10 ; score = -MAE\n",
    "scores = cross_val_score(model, X_train, y_train, scoring=\"neg_mean_absolute_error\", cv=10)\n",
    "# -MAE into MAE\n",
    "scores = -scores\n",
    "\n",
    "print(\n",
    "    f\"MAE moyenne : {scores.mean():.3f}\",\n",
    "    f\"Écart-type : {scores.std():.3f}\",\n",
    "    sep=\"\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8600721-7dd2-4495-bcb4-67dcc25d7b82",
   "metadata": {},
   "source": [
    "Après validation croisée, notre modèle nous semble largement moins convaincant ! Il ne nous reste plus qu’à tout reprendre de zéro et à travailler sur les différentes solutions pour l’améliorer : changer d’algorithme, augmenter le nombre d’observations d’entraînement ou encore lui imposer des contraintes afin de le régulariser.\n",
    "\n",
    "**Remarque :** le paramètre `scoring` de la fonction `cross_val_score()` attend une fonction d’utilité, où la valeur la plus haute est considérée comme la meilleure, et non une fonction de coût, où la valeur la plus basse est réputée la plus forte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a9905-1dd0-4f58-8eff-497ebb0e137c",
   "metadata": {},
   "source": [
    "#### Visualiser les courbes d’apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d87b9f5-a378-47d3-adda-96139041df20",
   "metadata": {},
   "source": [
    "Une bonne manière de se représenter les phénomènes de sous-ajustement et de sur-ajustement consiste à afficher les courbes de validation du modèle en fonction d’un paramètre avec la fonction `validation_curve()`. Dans notre exemple, nous avons utilisé un arbre de décision que l’on sait avoir tendance à sur-ajuster et nous sélectionnons deux paramètres réputés le régulariser : `max_depth` pour définir la profondeur maximale de l’arbre et `min_samples_leaf` pour fixer le nombre minimum d’observations à considérer dans un nœud de l’arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466eafb-b402-45a3-a218-8dbb59c24ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# several values for each param\n",
    "max_depth = [1, 4, 5, 7, 10, 25]\n",
    "min_samples_leaf = [1, 3, 5, 7, 10, 15]\n",
    "\n",
    "# param = max_depth ; score = -MAE\n",
    "max_depth_train_scores, max_depth_test_scores = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name=\"max_depth\", param_range=max_depth,\n",
    "    cv=10, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "# param = min_samples_leaf ; score = -MAE\n",
    "min_samples_leaf_train_scores, min_samples_leaf_test_scores = validation_curve(\n",
    "    model, X_train, y_train,\n",
    "    param_name=\"min_samples_leaf\", param_range=min_samples_leaf,\n",
    "    cv=10, scoring=\"neg_mean_absolute_error\"\n",
    ")\n",
    "\n",
    "# -MAE into MAE\n",
    "max_depth_train_errors, max_depth_test_errors = -max_depth_train_scores, -max_depth_test_scores\n",
    "min_samples_leaf_train_errors, min_samples_leaf_test_errors = -min_samples_leaf_train_scores, -min_samples_leaf_test_scores\n",
    "\n",
    "# plot\n",
    "figure, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n",
    "\n",
    "sns.lineplot(x=max_depth, y=train_errors.mean(axis=1), ax=ax1)\n",
    "sns.lineplot(x=max_depth, y=test_errors.mean(axis=1), ax=ax1)\n",
    "sns.lineplot(x=min_samples_leaf, y=train_errors.mean(axis=1), ax=ax2)\n",
    "sns.lineplot(x=min_samples_leaf, y=test_errors.mean(axis=1), ax=ax2)\n",
    "\n",
    "ax1.set(\n",
    "    title=\"Paramètre : max_depth\",\n",
    "    xlabel=\"Profondeur maximale de l’arbre\",\n",
    "    ylabel=\"Erreur absolue moyenne\"\n",
    ")\n",
    "ax2.set(\n",
    "    title=\"Paramètre : min_samples_leaf\",\n",
    "    xlabel=\"Nombre minimum d’observations dans un nœud\",\n",
    "    ylabel=\"Erreur absolue moyenne\"\n",
    ")\n",
    "ax1.legend([\"Entraînement\", \"Validation\"])\n",
    "ax2.legend([\"Entraînement\", \"Validation\"])\n",
    "\n",
    "figure.suptitle(\"Courbes de validation de l’arbre de décision\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ea4b0-6c2d-4460-81bd-947e0b52aef1",
   "metadata": {},
   "source": [
    "L’analyse des graphiques nous révèle les valeurs idéales pour les paramètres de régularisation :\n",
    "- `max_depth` : 5\n",
    "- `min_samples_leaf`: 3\n",
    "\n",
    "Pour chacun d’eux, nous distinguons trois zones :\n",
    "1. Tant que la valeur du paramètre est inférieure à celle idéale, le modèle sous-ajuste. Il n’a pas assez de degré de liberté pour comprendre toutes les variations de la variable cible. La MAE est forte pour les deux tracés.\n",
    "2. Lorsque le tracé de la MAE pour le jeu de validation cesse de décroître, le modèle a atteint la zone où il généralise le mieux.\n",
    "3. Sitôt que la valeur idéale est dépassée, le modèle s’ajuste de plus en plus étroitement aux données d’entraînement et généralise de moins en moins bien.\n",
    "\n",
    "À ces observations, il faut en rajouter une sur l’écart entre les deux tracés. Dans le cas du paramètre `min_samples_leaf`, on serait tenté·es de retenir la valeur 5 comme la meilleure puisque la MAE sur le jeu de validation reste stable alors qu’elle baisse sur le jeu d’entraînement. En fait, cet écart montre que le modèle est en train de sur-ajuster, aussi est-il préférable d’opter pour la valeur qui minimise l’écart.\n",
    "\n",
    "**Remarque :** les paramètres ont été testés individuellement, sans essayer les différentes combinaisons entre eux. Nous verrons plus loin une méthode pour effectuer une recherche des meilleurs réglages des hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfb17c2-578b-4956-ba8d-bd57970ea854",
   "metadata": {},
   "source": [
    "## Entraîner, tester, valider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf63f0a1-ca6f-4c2b-aa0a-96a6112f336c",
   "metadata": {},
   "source": [
    "## Régulariser un modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290a347-3c57-4203-b922-fada49ffc32c",
   "metadata": {},
   "source": [
    "## Sauvegarder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
